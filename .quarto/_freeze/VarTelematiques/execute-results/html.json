{
  "hash": "76cfb02d88818eca7a6b4ee7099aaa9a",
  "result": {
    "markdown": "# Telematic Covariates\n\n## Preamble\n\n::: {.panel-tabset}\n\n### Chapter Objective\n\nWe continue the analysis of claim frequency by adding telematic variables to the same three approaches of the last chapter. However, we will remove protected traditional variables from our analysis. Specifically, we will not use the following five covariates in our models:  \n\n  1) Credit.score,    \n  2) Insured.age,  \n  3) Insured.sex,  \n  4) Marital,  \n  5) Territory.\n\nThe objective is to assess the performance of ratemaking approaches incorporating telematics information without protected covariates. By analyzing the residuals of the approach, we will gauge the relevance of those protected covariates.\n\nTo compare models, we will employ the following functions that calculate predictive scores:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nScore.pred <- function(mu, x) {\n  Sc.log  <- -sum(dpois(x, mu, log=TRUE))\n  Sc.MSE  <- sum((x - mu)^2)\n  Sc.quad <- sum(-2*dpois(x,lambda=mu) + sapply(mu, function(x){ sum(dpois(0:10,lambda=x)^2) }))\n  Sc.sph <- sum(- dpois(x,mu) / sqrt(sapply(mu, function(x){ sum(dpois(0:10,lambda=x)^2) })))\n  Sc.DSS <- sum(dss_pois(x, mu))\n  Sc.CRPS <- sum(crps_pois(x, mu))\n    \n  return(c(Sc.log, Sc.MSE, Sc.quad, Sc.sph, Sc.DSS, Sc.CRPS))\n}\n```\n:::\n\n\n### Packages\n\nHere is the list of packages that will be used:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(vtable)\nlibrary(rpart)\nlibrary(repr)\nlibrary(rpart.plot)\nlibrary(gam)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(janitor)\nlibrary(glmnet)\nlibrary(scoringRules)\nlibrary(sjPlot)\n```\n:::\n\n\n### Data\n\nThe same data is used.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndataS <- read.csv('Data/Synthetic.csv')\n\n# Modifications \ndataS <- dataS %>%\n  mutate(Territory = as.factor(Territory)) %>%\n  select(-c('Annual.pct.driven', 'Annual.miles.drive'))\ndata.select <- dataS\n\n# Train-test \nset.seed(123)\ntrain <- data.select %>% sample_frac(0.8, replace = FALSE)\ntest <- data.select %>% anti_join(train)\n```\n:::\n\n\n### Data Transformation\n\nAs we concluded at the end of our overview of the data, a transformation of certain variables is also necessary.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Modif data\ntrain2 <- train %>%\n  mutate(Miles.per.day = Total.miles.driven/Duration,\n         max.day = pmax(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         min.day = pmin(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         max.min = max.day - min.day,\n         Dayformax = 'Monday', \n         Dayformax = ifelse(max.day == Pct.drive.tue, 'Tuesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.wed, 'Wednesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.thr, 'Thursday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.fri, 'Friday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sat, 'Saturday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sun, 'Sunday', Dayformax),\n         Dayformin = 'Monday', \n         Dayformin = ifelse(min.day == Pct.drive.tue, 'Tuesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.wed, 'Wednesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.thr, 'Thursday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.fri, 'Friday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sat, 'Saturday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sun, 'Sunday', Dayformin),\n         expo = Duration/365.25)\n\ntransform.fct <- function(var){\n  df <- train2 %>% mutate(var_ = get(var)*Total.miles.driven/(1000*Duration))\n  q99 <- quantile(df$var_, 0.99)\n  df <- df %>% mutate(var_ = ifelse(var_ > q99, q99, var_))\n  #colnames(df)[ncol(df)] <- paste0(var, '_')\n  return(df)\n}\n\ntrain2 <- transform.fct(\"Brake.06miles\")\ntrain2 <- transform.fct(\"Brake.08miles\")\ntrain2 <- transform.fct(\"Brake.09miles\")\ntrain2 <- transform.fct(\"Brake.11miles\")\ntrain2 <- transform.fct(\"Brake.14miles\")\ntrain2 <- transform.fct(\"Accel.06miles\")\ntrain2 <- transform.fct(\"Accel.08miles\")\ntrain2 <- transform.fct(\"Accel.09miles\")\ntrain2 <- transform.fct(\"Accel.11miles\")\ntrain2 <- transform.fct(\"Accel.12miles\")\ntrain2 <- transform.fct(\"Accel.14miles\")\ntrain2 <- transform.fct(\"Left.turn.intensity08\")\ntrain2 <- transform.fct(\"Left.turn.intensity09\")\ntrain2 <- transform.fct(\"Left.turn.intensity10\")\ntrain2 <- transform.fct(\"Left.turn.intensity11\")\ntrain2 <- transform.fct(\"Left.turn.intensity12\")\ntrain2 <- transform.fct(\"Right.turn.intensity08\")\ntrain2 <- transform.fct(\"Right.turn.intensity09\")\ntrain2 <- transform.fct(\"Right.turn.intensity10\")\ntrain2 <- transform.fct(\"Right.turn.intensity11\")\ntrain2 <- transform.fct(\"Right.turn.intensity12\")\n\n# Create folds\nnb.fold <- 5\nfold <- sample(1:nb.fold, nrow(train2), replace = TRUE)\ntrain2$fold <- fold\n\n##\n\ntest2 <- test %>%\n  mutate(Miles.per.day = Total.miles.driven/Duration,\n         max.day = pmax(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         min.day = pmin(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         max.min = max.day - min.day,\n         Dayformax = 'Monday', \n         Dayformax = ifelse(max.day == Pct.drive.tue, 'Tuesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.wed, 'Wednesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.thr, 'Thursday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.fri, 'Friday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sat, 'Saturday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sun, 'Sunday', Dayformax),\n         Dayformin = 'Monday', \n         Dayformin = ifelse(min.day == Pct.drive.tue, 'Tuesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.wed, 'Wednesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.thr, 'Thursday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.fri, 'Friday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sat, 'Saturday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sun, 'Sunday', Dayformin),\n         expo = Duration/365.25)\n\ntransform.fct <- function(var){\n  df <- test2 %>% mutate(var_ = get(var)*Total.miles.driven/(1000*Duration))\n  q99 <- quantile(df$var_, 0.99)\n  df <- df %>% mutate(var_ = ifelse(var_ > q99, q99, var_))\n  #colnames(df)[ncol(df)] <- paste0(var, '_')\n  return(df)\n}\n\ntest2 <- transform.fct(\"Brake.06miles\")\ntest2 <- transform.fct(\"Brake.08miles\")\ntest2 <- transform.fct(\"Brake.09miles\")\ntest2 <- transform.fct(\"Brake.11miles\")\ntest2 <- transform.fct(\"Brake.14miles\")\ntest2 <- transform.fct(\"Accel.06miles\")\ntest2 <- transform.fct(\"Accel.08miles\")\ntest2 <- transform.fct(\"Accel.09miles\")\ntest2 <- transform.fct(\"Accel.11miles\")\ntest2 <- transform.fct(\"Accel.12miles\")\ntest2 <- transform.fct(\"Accel.14miles\")\ntest2 <- transform.fct(\"Left.turn.intensity08\")\ntest2 <- transform.fct(\"Left.turn.intensity09\")\ntest2 <- transform.fct(\"Left.turn.intensity10\")\ntest2 <- transform.fct(\"Left.turn.intensity11\")\ntest2 <- transform.fct(\"Left.turn.intensity12\")\ntest2 <- transform.fct(\"Right.turn.intensity08\")\ntest2 <- transform.fct(\"Right.turn.intensity09\")\ntest2 <- transform.fct(\"Right.turn.intensity10\")\ntest2 <- transform.fct(\"Right.turn.intensity11\")\ntest2 <- transform.fct(\"Right.turn.intensity12\")\n\n# Mean Encoding with White Noise pour les territoires\ncardi <- length(unique(train$Territory))\n\nenc.terr <- train2 %>%\n  group_by(Territory) %>%\n  summarize(freq = sum(NB_Claim)/sum(expo)) %>%\n  arrange(freq) %>%\n  mutate(terr.code= row_number()/(cardi+1)) %>%\n  select(Territory, terr.code)\n\ntrain2 <- train2 %>%\n  group_by(Territory) %>%\n  left_join(enc.terr, by='Territory') %>%\n  ungroup()\n\ntest2 <- test2 %>%\n  group_by(Territory) %>%\n  left_join(enc.terr, by='Territory') %>%\n  ungroup()\n```\n:::\n\n\n:::\n\n## Basic GLM Models\n\n::: {.panel-tabset}\n\n### Single intercept\n\nA baseline model corresponding to a Generalized Linear Model (GLM) with intercept and predicting for each contract only the observed mean multiplied by the exposure is used as a point of comparison.\n\n\n::: {#tbl-Pscore_base .cell tbl-cap='Prediction scores for the base model'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model on each fold\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n    learn <- train2[train2$fold != i,]\n    valid <- train2[train2$fold == i,]\n\n    mean <- sum(learn$NB_Claim)/sum(learn$expo) \n    learn$pred.base <- mean*learn$expo\n    valid$pred.base <- mean*valid$expo\n\n    Result_ <- rbind(Result_, c(i, Score.pred(valid$pred.base, valid$NB_Claim)/nrow(valid)))\n    Result2_ <- rbind(Result2_, c(i, Score.pred(valid$pred.base, valid$NB_Claim)))\n}\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\n\nResult.base <- Result_  \nBase <- Result.base[nb.fold+1,]\n\nknitr::kable(Result_, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.18212 </td>\n   <td style=\"text-align:center;\"> 0.04666 </td>\n   <td style=\"text-align:center;\"> -0.91794 </td>\n   <td style=\"text-align:center;\"> -0.95797 </td>\n   <td style=\"text-align:center;\"> -2.16359 </td>\n   <td style=\"text-align:center;\"> 0.04283 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0.18185 </td>\n   <td style=\"text-align:center;\"> 0.04681 </td>\n   <td style=\"text-align:center;\"> -0.91869 </td>\n   <td style=\"text-align:center;\"> -0.95838 </td>\n   <td style=\"text-align:center;\"> -2.14758 </td>\n   <td style=\"text-align:center;\"> 0.04263 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 0.17509 </td>\n   <td style=\"text-align:center;\"> 0.04555 </td>\n   <td style=\"text-align:center;\"> -0.92361 </td>\n   <td style=\"text-align:center;\"> -0.96096 </td>\n   <td style=\"text-align:center;\"> -2.17549 </td>\n   <td style=\"text-align:center;\"> 0.04057 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 0.19451 </td>\n   <td style=\"text-align:center;\"> 0.05149 </td>\n   <td style=\"text-align:center;\"> -0.91176 </td>\n   <td style=\"text-align:center;\"> -0.95472 </td>\n   <td style=\"text-align:center;\"> -2.06650 </td>\n   <td style=\"text-align:center;\"> 0.04650 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0.18543 </td>\n   <td style=\"text-align:center;\"> 0.04832 </td>\n   <td style=\"text-align:center;\"> -0.91673 </td>\n   <td style=\"text-align:center;\"> -0.95733 </td>\n   <td style=\"text-align:center;\"> -2.13131 </td>\n   <td style=\"text-align:center;\"> 0.04382 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 0.18379 </td>\n   <td style=\"text-align:center;\"> 0.04777 </td>\n   <td style=\"text-align:center;\"> -0.91775 </td>\n   <td style=\"text-align:center;\"> -0.95787 </td>\n   <td style=\"text-align:center;\"> -2.13689 </td>\n   <td style=\"text-align:center;\"> 0.04327 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe model is trained on the entire training dataset and subsequently tested on the untouched test dataset, ensuring that the parameter calibration process remains independent from the test data.\n\n\n::: {#tbl-Pscore_basetest .cell tbl-cap='Prediction scores for the base model (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nmean <- sum(train2$NB_Claim)/sum(train2$expo) \ntest2$pred.base <- mean*test2$expo\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('Base', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- Result_\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Traditional covariates already used (without protected variables)\n\nFor comparison, we start with a simple GLM model considering only the traditional covariates (excluding the protected variables). Therefore, we include:  \n\n  - Car.use,  \n  - Region,  \n  - Car.age, \n  - Years.noclaims.  \n\nThe model's prediction scores are displayed below. As expected, adding segmentation variables improves the prediction scores compared to the simple baseline model with only an intercept.\n\n\n::: {#tbl-TeleGLM2 .cell tbl-cap='Prediction scores for the GLM model with traditional covariates (without protected)'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model \nscore.base <- as.formula(NB_Claim ~ 1 + offset(log(expo)))\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                        + offset(log(expo)))\n## Model on each fold\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n    learn <- train2[train2$fold != i,]\n    valid <- train2[train2$fold == i,]\n    glm.fit <- glm(score.glm, family = poisson(), data = learn)\n\n    learn$pred.base <- predict(glm.fit, newdata=learn, type='response')\n    valid$pred.base <- predict(glm.fit, newdata=valid, type='response')\n\n    Result_ <- rbind(Result_, c(i, Score.pred(valid$pred.base, valid$NB_Claim)/nrow(valid)))\n    Result2_ <- rbind(Result2_, c(i, Score.pred(valid$pred.base, valid$NB_Claim)))\n}\n\n## Model on all data from train\nglm.base <- glm(score.base, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\ntrain2$pred.glm1 <- predict(glm.fit, newdata=train2, type='response')\nResult.glm1 <- Result_  \n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:7){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.17859 </td>\n   <td style=\"text-align:center;\"> 0.04632 </td>\n   <td style=\"text-align:center;\"> -0.91850 </td>\n   <td style=\"text-align:center;\"> -0.95813 </td>\n   <td style=\"text-align:center;\"> -2.26779 </td>\n   <td style=\"text-align:center;\"> 0.04253 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0.17983 </td>\n   <td style=\"text-align:center;\"> 0.04658 </td>\n   <td style=\"text-align:center;\"> -0.91905 </td>\n   <td style=\"text-align:center;\"> -0.95848 </td>\n   <td style=\"text-align:center;\"> -2.12885 </td>\n   <td style=\"text-align:center;\"> 0.04243 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 0.17133 </td>\n   <td style=\"text-align:center;\"> 0.04523 </td>\n   <td style=\"text-align:center;\"> -0.92405 </td>\n   <td style=\"text-align:center;\"> -0.96107 </td>\n   <td style=\"text-align:center;\"> -2.30038 </td>\n   <td style=\"text-align:center;\"> 0.04031 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 0.19041 </td>\n   <td style=\"text-align:center;\"> 0.05106 </td>\n   <td style=\"text-align:center;\"> -0.91249 </td>\n   <td style=\"text-align:center;\"> -0.95493 </td>\n   <td style=\"text-align:center;\"> -2.15895 </td>\n   <td style=\"text-align:center;\"> 0.04611 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0.18255 </td>\n   <td style=\"text-align:center;\"> 0.04803 </td>\n   <td style=\"text-align:center;\"> -0.91717 </td>\n   <td style=\"text-align:center;\"> -0.95744 </td>\n   <td style=\"text-align:center;\"> -2.22301 </td>\n   <td style=\"text-align:center;\"> 0.04358 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 0.18054 </td>\n   <td style=\"text-align:center;\"> 0.04744 </td>\n   <td style=\"text-align:center;\"> -0.91826 </td>\n   <td style=\"text-align:center;\"> -0.95801 </td>\n   <td style=\"text-align:center;\"> -2.21586 </td>\n   <td style=\"text-align:center;\"> 0.04299 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.00326 </td>\n   <td style=\"text-align:center;\"> -0.00032 </td>\n   <td style=\"text-align:center;\"> -0.00051 </td>\n   <td style=\"text-align:center;\"> -0.00014 </td>\n   <td style=\"text-align:center;\"> -0.07896 </td>\n   <td style=\"text-align:center;\"> -0.00028 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe comparison with the test dataset is also depicted in the table below. \n\n\n::: {#tbl-Pscore_basetest2 .cell tbl-cap='Prediction scores for the GLM model with traditional covariates (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                        + offset(log(expo)))\n\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\ntest2$pred.base <- predict(glm.fit, newdata=test2, type='response')\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('GLM (trad.)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Estimated Parameters\n\nThe table below shows the estimators obtained for the GLM-Poisson approach and compares them with the baseline model, which has only an intercept.\n\n\n::: {#tbl-TeleGLM1 .cell tbl-cap='Estimated parameters for the GLM model with traditional covariates (without protected)'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model \nscore.base <- as.formula(NB_Claim ~ 1 + offset(log(expo)))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                        + offset(log(expo)))\n\n## Model on all data from train\nglm.base <- glm(score.base, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ntab_model(glm.base, glm.fit, transform = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">NB Claim</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">NB Claim</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Mean</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Mean</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.94</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.98&nbsp;&ndash;&nbsp;-2.91</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.78</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.00&nbsp;&ndash;&nbsp;-1.56</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Commute]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.32</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.47&nbsp;&ndash;&nbsp;-0.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Farmer]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.84</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.37&nbsp;&ndash;&nbsp;-0.38</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Private]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.62&nbsp;&ndash;&nbsp;-0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Region [Urban]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.05&nbsp;&ndash;&nbsp;0.22</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.002</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car age</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.05&nbsp;&ndash;&nbsp;-0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.028</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car age^2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.01&nbsp;&ndash;&nbsp;-0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Years noclaims</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.09&nbsp;&ndash;&nbsp;-0.05</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Years noclaims^2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Years noclaims^3</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00&nbsp;&ndash;&nbsp;-0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">80000</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">80000</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Nagelkerke</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.000</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.028</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::\n\n## GLM-Net\n\n### Parametric transformation of continuous covariates\n\nNow, we add all available telematic variables to the model. Similar to the approach taken in the previous chapter, we will introduce a method utilizing the Generalized Additive Models (GAM) theory for all these continuous variables. This will enable us to observe the general form of the covariate to explain the number of claims. Subsequently, a parametric form will be proposed to achieve the best possible correspondence with the spline obtained by the GAM.\n\n::: {.panel-tabset}\n\n### VEHICLE USAGE LEVEL\n\nFor the two covariates related to usage level, the proposed parametric forms are as follows:\n\n\\begin{align*}\ns(Miles.per.day) &\\approx Miles.per.day + log(Miles.per.day)\\\\\ns(Avgdays.week) &\\approx Avgdays.week + Avgdays.week^2\n\\end{align*}\n\nThe graphs below compare the fit of the parametric approach with that of the GAM model.\n\n\n\n::: {#fig-MpD_GAM_sev_tel .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmin_ <- min(train2$Miles.per.day) \nmax_ <- max(train2$Miles.per.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'Miles.per.day'\n\nq99 <- quantile(train2$Miles.per.day, 0.99)\n\ndb <- train2 %>%\n  select(-'Miles.per.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(Miles.per.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + Miles.per.day + log(Miles.per.day) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(Miles.per.day - mean(train2$Miles.per.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=Miles.per.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=Miles.per.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Miles per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n### Avgdays.week\n\nmin_ <- min(train2$Avgdays.week) \nmax_ <- max(train2$Avgdays.week) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'Avgdays.week'\n\nq99 <- quantile(train2$Avgdays.week, 0.99)\n\ndb <- train2 %>%\n  select(-'Avgdays.week') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(Avgdays.week))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + Avgdays.week + I(Avgdays.week^2) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(Avgdays.week - mean(train2$Avgdays.week))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=Avgdays.week, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=Avgdays.week, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Avgdays.week',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n```\n\n::: {.cell-output-display}\n![Miles.per.day](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel-1.png){#fig-MpD_GAM_sev_tel-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Avgdays.week](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel-2.png){#fig-MpD_GAM_sev_tel-2 width=672}\n:::\n\nSmoothing of Usage level covariates\n:::\n\n\n### Type of Vehicle Usage\n\n\nSeveral covariates are available in the category *Type of vehicle usage*:  \n\n- We propose the same parametric form for all variants of the variable *Pct.drive.day* (Monday to Sunday);  \n- The same parametric form will also be proposed for *Pct.drive.rush.am*, *Pct.drive.rush.pm*, *Pct.drive.2hrs*, *Pct.drive.3hrs*, and *Pct.drive.4hrs*;  \n- The other three covariates have their own parametric form.\n\nWe then have:\n\n\\begin{align*}\ns(Pct.drive.day) &\\approx Pct.drive.day + Pct.drive.day^2 \\\\\ns(Pct.drive) &\\approx Pct.drive + \\sqrt{Pct.drive} \\\\\ns(max.day) &\\approx max.day + \\log(max.day) \\\\\ns(min.day) &\\approx min.day + min.day^2 \\\\\ns(max.min) &\\approx max.min + max.min^2 \n\\end{align*}\n\n\n\n::: {#fig-MpD_GAM_sev_tel3 .cell layout-nrow=\"3\" layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ntrain2$Pct.drive <- train2$Pct.drive.sun\n\nmin_ <- min(train2$Pct.drive) \nmax_ <- max(train2$Pct.drive) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'Pct.drive'\n\nq99 <- quantile(train2$Pct.drive, 0.99)\n\ndb <- train2 %>%\n  select(-'Pct.drive') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(Pct.drive))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + Pct.drive + I(Pct.drive^2) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(Pct.drive - mean(train2$Pct.drive))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=Pct.drive, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=Pct.drive, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Pct.drive',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n### Pct.drive \n\n\ntrain2$use.day <- train2$Pct.drive.rush.am\n\nmin_ <- min(train2$use.day) \nmax_ <- max(train2$use.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\nq99 <- quantile(train2$use.day, 0.99)\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + use.day + I(use.day^0.5))\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(train2$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n\n### Max day\n\ntrain2$use.day <- train2$max.day\n\nmin_ <- min(train2$use.day) \nmax_ <- max(train2$use.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\nq99 <- quantile(train2$use.day, 0.99)\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + use.day + log(use.day) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(train2$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n### Min day\n\n\ntrain2$use.day <- train2$min.day\n\nmin_ <- min(train2$use.day) \nmax_ <- max(train2$use.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\nq99 <- quantile(train2$use.day, 0.99)\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + use.day + I(use.day^2) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(train2$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n### Max min\n\ntrain2$use.day <- train2$max.min\n\nmin_ <- min(train2$use.day) \nmax_ <- max(train2$use.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\nq99 <- quantile(train2$use.day, 0.99)\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + use.day + I(use.day^2) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(train2$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n```\n\n::: {.cell-output-display}\n![Pct.drive.mon](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel3-1.png){#fig-MpD_GAM_sev_tel3-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Pct.drive.rush.am](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel3-2.png){#fig-MpD_GAM_sev_tel3-2 width=672}\n:::\n\n::: {.cell-output-display}\n![max.day](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel3-3.png){#fig-MpD_GAM_sev_tel3-3 width=672}\n:::\n\n::: {.cell-output-display}\n![min.day](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel3-4.png){#fig-MpD_GAM_sev_tel3-4 width=672}\n:::\n\n::: {.cell-output-display}\n![max.min](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel3-5.png){#fig-MpD_GAM_sev_tel3-5 width=672}\n:::\n\nSmoothing of Type of vehicle usage covariates (severity)\n:::\n\n\n\n### Driving Behavior\n\nThe same parametric form is proposed for the different variants of the *Accel* and *Brake* variables, i.e., *Accel.06miles* to *Accel.14miles*, and *Brake.06miles* to *Brake.14miles*.  For the different variants of the *turn* variable, a single parametric form is also used: \n\n\\begin{align*}\ns(Brake.Accel) &\\approx Brake.Accel + Brake.Accel^2 + Brake.Accel^3\\\\\ns(Turn) &\\approx Turn + log(Turn)\n\\end{align*}\n\nThe graphs below compare the fit of the parametric approach for *Accel.06miles* and *Right.turn.intensity08* with that of the GAM model. \n\n\n::: {#fig-MpD_GAM_sev_tel2 .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ntrain2$use.day <- train2$Accel.06miles\n\nmin_ <- min(train2$use.day) \nmax_ <- max(train2$use.day) \nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\nq99 <- quantile(train2$use.day, 0.99)\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + use.day + I(use.day^2) + I(use.day^3) )\n\ngam.fit <- gam(score.gam, family = poisson(), data = train2)\nglm.fit <- glm(score.glm, family = poisson(), data = train2)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(train2$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n\nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n  xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n\n### Right and left turns\n\n\ntrain2$use.day <- train2$Right.turn.intensity08\n\nq99 <- quantile(train2$use.day, 0.99)\n\nmin_ <- min(train2$use.day) \nmax_ <- q99\nby_ <-  (max_ - min_)/(nrow(train2)-1) \nadd <- data.frame(seq(min_, max_, by_)) \ncolnames(add) <- 'use.day'\n\ndb <- train2 %>%\n  select(-'use.day') %>%\n  slice(1) \ndb <- bind_rows(replicate(nrow(train2), db, simplify = FALSE))\ndb <- cbind(db, add)\n\n##\n\ntemp <- train2 %>%\n  mutate(use.day = pmin(q99, use.day))\n\nscore.gam <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                        + s(use.day))\n\nscore.glm <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) + offset(log(expo))\n                         + use.day + log1p(use.day))\n\ngam.fit <- gam(score.gam, family = poisson(), data = temp)\nglm.fit <- glm(score.glm, family = poisson(), data = temp)\n\ndb$pred.gam <- predict(gam.fit, newdata=db, type='response')\ndb$pred.glm <- predict(glm.fit, newdata=db, type='response')\nbase <- db %>%\n  mutate(diff = abs(use.day - mean(temp$use.day))) %>%\n  filter(diff == min(diff))\ndb$pred.gam <- db$pred.gam/base$pred.gam[1]\ndb$pred.glm <- db$pred.glm/base$pred.glm[1]\n  \nggplot()+\n  geom_line(aes(x=use.day, y=pred.gam, color='GAM'), data=db) + \n  geom_line(aes(x=use.day, y=pred.glm, color='Parametric GLM'), data=db) +\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Use per day',\n       y = 'Relativity') +\n # xlim(0, q99) +\n  theme_classic()+\n   theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n```\n\n::: {.cell-output-display}\n![Accel.06miles](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel2-1.png){#fig-MpD_GAM_sev_tel2-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Right.turn.intensity08](VarTelematiques_files/figure-html/fig-MpD_GAM_sev_tel2-2.png){#fig-MpD_GAM_sev_tel2-2 width=672}\n:::\n\nSmoothing of Driving behavior covariates (severity)\n:::\n\n\n:::\n\n### Fitting the GLM-Net model\n\n\n::: {.cell}\n\n:::\n\n\n::: {.panel-tabset}\n\n### Optimal value\n\nThe parameters of the GLM-net were calibrated using cross-validation to obtain the model's hyperparameters. Using these values, we can calculate the prediction scores of the model based on all covariates.\n\n\n::: {#tbl-Pscore_teleGLMnet1 .cell tbl-cap='Prediction scores for the GLM-net model (alpha=1)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3)\n                        + Dayformax + Dayformin +\n                        + Miles.per.day + log(Miles.per.day)\n                        + Avgdays.week + I(Avgdays.week^2)\n                        + Pct.drive.mon + I(Pct.drive.mon^2)\n                        + Pct.drive.tue + I(Pct.drive.tue^2)\n                        + Pct.drive.wed + I(Pct.drive.wed^2)\n                        + Pct.drive.thr + I(Pct.drive.thr^2)\n                        + Pct.drive.fri + I(Pct.drive.fri^2)\n                        + Pct.drive.sat + I(Pct.drive.sat^2)\n                        + Pct.drive.sun + I(Pct.drive.sun^2)\n                        + Pct.drive.wkend + I(Pct.drive.wkend^2)\n                        + max.day + log(max.day) \n                        + min.day + I(min.day^2)\n                        + max.min + I(max.min^2)\n                        + Pct.drive.rush.am + sqrt(Pct.drive.rush.am) \n                        + Pct.drive.rush.pm + sqrt(Pct.drive.rush.pm)   \n                        + Pct.drive.2hrs + sqrt(Pct.drive.2hrs) \n                        + Pct.drive.3hrs + sqrt(Pct.drive.3hrs) \n                        + Pct.drive.4hrs + sqrt(Pct.drive.4hrs) \n                        + Accel.06miles + I(Accel.06miles^2) + I(Accel.06miles^3)\n                        + Accel.08miles + I(Accel.08miles^2) + I(Accel.08miles^3)\n                        + Accel.09miles + I(Accel.09miles^2) + I(Accel.09miles^3)\n                        + Accel.11miles + I(Accel.11miles^2) + I(Accel.11miles^3)\n                        + Accel.12miles + I(Accel.12miles^2) + I(Accel.12miles^3)\n                        + Accel.14miles + I(Accel.14miles^2) + I(Accel.14miles^3)\n                        + Brake.06miles + I(Brake.06miles^2) + I(Brake.06miles^3)\n                        + Brake.08miles + I(Brake.08miles^2) + I(Brake.08miles^3)\n                        + Brake.09miles + I(Brake.09miles^2) + I(Brake.09miles^3)\n                        + Brake.11miles + I(Brake.11miles^2) + I(Brake.11miles^3)\n                        + Brake.12miles + I(Brake.12miles^2) + I(Brake.12miles^3)\n                        + Brake.14miles + I(Brake.14miles^2) + I(Brake.14miles^3)\n                        + Left.turn.intensity08 + log1p(Left.turn.intensity08)\n                        + Left.turn.intensity09 + log1p(Left.turn.intensity09)\n                        + Left.turn.intensity10 + log1p(Left.turn.intensity10)\n                        + Left.turn.intensity11 + log1p(Left.turn.intensity11)\n                        + Left.turn.intensity12 + log1p(Left.turn.intensity12)\n                        + Right.turn.intensity08 + log1p(Right.turn.intensity08)\n                        + Right.turn.intensity09 + log1p(Right.turn.intensity09)\n                        + Right.turn.intensity10 + log1p(Right.turn.intensity10)\n                        + Right.turn.intensity11 + log1p(Right.turn.intensity11)\n                        + Right.turn.intensity12 + log1p(Right.turn.intensity12))\n\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n    learn <- train2[train2$fold != i,]\n    valid <- train2[train2$fold == i,]\n    \n    matrix.x <- model.matrix(glm.score, data=learn)[,-1]\n    y <- learn$NB_Claim\n    offset <- log(learn$expo)\n\n    lambda.min <- 3.981072e-05\n    lambda.1se <- 0.001258925\n    \n    lambda.select <- lambda.min\n    fit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\n    #fit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n  \n    matrix.x <- model.matrix(glm.score, data=valid)[,-1]\n    y <- valid$NB_Claim\n    offset <- log(valid$expo)\n\n    valid$pred <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n    \n    Result_ <- rbind(Result_, c(i, Score.pred(valid$pred, valid$NB_Claim)/nrow(valid)))\n    Result2_ <- rbind(Result2_, c(i, Score.pred(valid$pred, valid$NB_Claim)))\n}\n\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:7){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.16065 </td>\n   <td style=\"text-align:center;\"> 0.04360 </td>\n   <td style=\"text-align:center;\"> -0.92280 </td>\n   <td style=\"text-align:center;\"> -0.95956 </td>\n   <td style=\"text-align:center;\"> -2.84021 </td>\n   <td style=\"text-align:center;\"> 0.04018 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0.15958 </td>\n   <td style=\"text-align:center;\"> 0.04302 </td>\n   <td style=\"text-align:center;\"> -0.92380 </td>\n   <td style=\"text-align:center;\"> -0.96009 </td>\n   <td style=\"text-align:center;\"> 512.20739 </td>\n   <td style=\"text-align:center;\"> 0.03970 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 0.15391 </td>\n   <td style=\"text-align:center;\"> 0.04248 </td>\n   <td style=\"text-align:center;\"> -0.92795 </td>\n   <td style=\"text-align:center;\"> -0.96228 </td>\n   <td style=\"text-align:center;\"> 5.94017 </td>\n   <td style=\"text-align:center;\"> 0.03807 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 0.16786 </td>\n   <td style=\"text-align:center;\"> 0.04706 </td>\n   <td style=\"text-align:center;\"> -0.91797 </td>\n   <td style=\"text-align:center;\"> -0.95674 </td>\n   <td style=\"text-align:center;\"> -2.67292 </td>\n   <td style=\"text-align:center;\"> 0.04298 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0.16300 </td>\n   <td style=\"text-align:center;\"> 0.04500 </td>\n   <td style=\"text-align:center;\"> -0.92166 </td>\n   <td style=\"text-align:center;\"> -0.95890 </td>\n   <td style=\"text-align:center;\"> -2.76580 </td>\n   <td style=\"text-align:center;\"> 0.04106 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 0.16099 </td>\n   <td style=\"text-align:center;\"> 0.04424 </td>\n   <td style=\"text-align:center;\"> -0.92284 </td>\n   <td style=\"text-align:center;\"> -0.95952 </td>\n   <td style=\"text-align:center;\"> 101.77054 </td>\n   <td style=\"text-align:center;\"> 0.04039 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.02280 </td>\n   <td style=\"text-align:center;\"> -0.00353 </td>\n   <td style=\"text-align:center;\"> -0.00509 </td>\n   <td style=\"text-align:center;\"> -0.00164 </td>\n   <td style=\"text-align:center;\"> 103.90744 </td>\n   <td style=\"text-align:center;\"> -0.00287 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOn the *test* set, we obtain:\n\n\n::: {#tbl-Pscore_basetest3 .cell tbl-cap='Prediction scores for the GLM-net model  (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3)\n                        + Dayformax + Dayformin +\n                        + Miles.per.day + log(Miles.per.day)\n                        + Avgdays.week + I(Avgdays.week^2)\n                        + Pct.drive.mon + I(Pct.drive.mon^2)\n                        + Pct.drive.tue + I(Pct.drive.tue^2)\n                        + Pct.drive.wed + I(Pct.drive.wed^2)\n                        + Pct.drive.thr + I(Pct.drive.thr^2)\n                        + Pct.drive.fri + I(Pct.drive.fri^2)\n                        + Pct.drive.sat + I(Pct.drive.sat^2)\n                        + Pct.drive.sun + I(Pct.drive.sun^2)\n                        + Pct.drive.wkend + I(Pct.drive.wkend^2)\n                        + max.day + log(max.day) \n                        + min.day + I(min.day^2)\n                        + max.min + I(max.min^2)\n                        + Pct.drive.rush.am + sqrt(Pct.drive.rush.am) \n                        + Pct.drive.rush.pm + sqrt(Pct.drive.rush.pm)   \n                        + Pct.drive.2hrs + sqrt(Pct.drive.2hrs) \n                        + Pct.drive.3hrs + sqrt(Pct.drive.3hrs) \n                        + Pct.drive.4hrs + sqrt(Pct.drive.4hrs) \n                        + Accel.06miles + I(Accel.06miles^2) + I(Accel.06miles^3)\n                        + Accel.08miles + I(Accel.08miles^2) + I(Accel.08miles^3)\n                        + Accel.09miles + I(Accel.09miles^2) + I(Accel.09miles^3)\n                        + Accel.11miles + I(Accel.11miles^2) + I(Accel.11miles^3)\n                        + Accel.12miles + I(Accel.12miles^2) + I(Accel.12miles^3)\n                        + Accel.14miles + I(Accel.14miles^2) + I(Accel.14miles^3)\n                        + Brake.06miles + I(Brake.06miles^2) + I(Brake.06miles^3)\n                        + Brake.08miles + I(Brake.08miles^2) + I(Brake.08miles^3)\n                        + Brake.09miles + I(Brake.09miles^2) + I(Brake.09miles^3)\n                        + Brake.11miles + I(Brake.11miles^2) + I(Brake.11miles^3)\n                        + Brake.12miles + I(Brake.12miles^2) + I(Brake.12miles^3)\n                        + Brake.14miles + I(Brake.14miles^2) + I(Brake.14miles^3)\n                        + Left.turn.intensity08 + log1p(Left.turn.intensity08)\n                        + Left.turn.intensity09 + log1p(Left.turn.intensity09)\n                        + Left.turn.intensity10 + log1p(Left.turn.intensity10)\n                        + Left.turn.intensity11 + log1p(Left.turn.intensity11)\n                        + Left.turn.intensity12 + log1p(Left.turn.intensity12)\n                        + Right.turn.intensity08 + log1p(Right.turn.intensity08)\n                        + Right.turn.intensity09 + log1p(Right.turn.intensity09)\n                        + Right.turn.intensity10 + log1p(Right.turn.intensity10)\n                        + Right.turn.intensity11 + log1p(Right.turn.intensity11)\n                        + Right.turn.intensity12 + log1p(Right.turn.intensity12))\n\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$NB_Claim\noffset <- log(train2$expo)\n\nlambda.min <- 3.981072e-05\nlambda.1se <- 0.001258925\n    \nlambda.select <- lambda.min\nfit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\n#fit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n\ntrain2$pred.tele <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n\nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$NB_Claim\noffset <- log(test2$expo)\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('LASSO (optimal)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15536 </td>\n   <td style=\"text-align:center;\"> 0.04239 </td>\n   <td style=\"text-align:center;\"> -0.92624 </td>\n   <td style=\"text-align:center;\"> -0.96135 </td>\n   <td style=\"text-align:center;\"> -2.69596 </td>\n   <td style=\"text-align:center;\"> 0.03866 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n### Parsimonious model\n\nInstead of using the optimal value of the penalty $\\lambda$  in the elastic-net approach, it is often advised to use a penalty value located at one standard error ($\\lambda_{1se}$). This helps to obtain a more parsimonious model. The prediction scores of such a model are displayed below.\n\n\n::: {#tbl-Pscore_GLMnet2 .cell tbl-cap='Prediction scores for the GLM-net model (alpha=1)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n    learn <- train2[train2$fold != i,]\n    valid <- train2[train2$fold == i,]\n    \n    matrix.x <- model.matrix(glm.score, data=learn)[,-1]\n    y <- learn$NB_Claim\n    offset <- log(learn$expo)\n\n    lambda.min <- 3.981072e-05\n    lambda.1se <- 0.001258925\n    \n    lambda.select <- lambda.1se\n    #fit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\n    fit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n  \n    matrix.x <- model.matrix(glm.score, data=valid)[,-1]\n    y <- valid$NB_Claim\n    offset <- log(valid$expo)\n\n    valid$pred <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n    \n    Result_ <- rbind(Result_, c(i, Score.pred(valid$pred, valid$NB_Claim)/nrow(valid)))\n    Result2_ <- rbind(Result2_, c(i, Score.pred(valid$pred, valid$NB_Claim)))\n}\n\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:7){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.16141 </td>\n   <td style=\"text-align:center;\"> 0.04348 </td>\n   <td style=\"text-align:center;\"> -0.92233 </td>\n   <td style=\"text-align:center;\"> -0.95936 </td>\n   <td style=\"text-align:center;\"> -2.76915 </td>\n   <td style=\"text-align:center;\"> 0.04033 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0.16045 </td>\n   <td style=\"text-align:center;\"> 0.04370 </td>\n   <td style=\"text-align:center;\"> -0.92307 </td>\n   <td style=\"text-align:center;\"> -0.95975 </td>\n   <td style=\"text-align:center;\"> -2.72663 </td>\n   <td style=\"text-align:center;\"> 0.04015 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 0.15505 </td>\n   <td style=\"text-align:center;\"> 0.04271 </td>\n   <td style=\"text-align:center;\"> -0.92730 </td>\n   <td style=\"text-align:center;\"> -0.96203 </td>\n   <td style=\"text-align:center;\"> -2.73338 </td>\n   <td style=\"text-align:center;\"> 0.03840 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 0.16975 </td>\n   <td style=\"text-align:center;\"> 0.04763 </td>\n   <td style=\"text-align:center;\"> -0.91721 </td>\n   <td style=\"text-align:center;\"> -0.95642 </td>\n   <td style=\"text-align:center;\"> -2.65287 </td>\n   <td style=\"text-align:center;\"> 0.04342 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0.16418 </td>\n   <td style=\"text-align:center;\"> 0.04518 </td>\n   <td style=\"text-align:center;\"> -0.92116 </td>\n   <td style=\"text-align:center;\"> -0.95868 </td>\n   <td style=\"text-align:center;\"> -2.69140 </td>\n   <td style=\"text-align:center;\"> 0.04131 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 0.16216 </td>\n   <td style=\"text-align:center;\"> 0.04454 </td>\n   <td style=\"text-align:center;\"> -0.92222 </td>\n   <td style=\"text-align:center;\"> -0.95925 </td>\n   <td style=\"text-align:center;\"> -2.71461 </td>\n   <td style=\"text-align:center;\"> 0.04072 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.02163 </td>\n   <td style=\"text-align:center;\"> -0.00323 </td>\n   <td style=\"text-align:center;\"> -0.00447 </td>\n   <td style=\"text-align:center;\"> -0.00137 </td>\n   <td style=\"text-align:center;\"> -0.57772 </td>\n   <td style=\"text-align:center;\"> -0.00255 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOn the *test* set, we obtain:\n\n\n::: {#tbl-Pscore_basetest4 .cell tbl-cap='Prediction scores for the GLM-net model  (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3)\n                        + Dayformax + Dayformin +\n                        + Miles.per.day + log(Miles.per.day)\n                        + Avgdays.week + I(Avgdays.week^2)\n                        + Pct.drive.mon + I(Pct.drive.mon^2)\n                        + Pct.drive.tue + I(Pct.drive.tue^2)\n                        + Pct.drive.wed + I(Pct.drive.wed^2)\n                        + Pct.drive.thr + I(Pct.drive.thr^2)\n                        + Pct.drive.fri + I(Pct.drive.fri^2)\n                        + Pct.drive.sat + I(Pct.drive.sat^2)\n                        + Pct.drive.sun + I(Pct.drive.sun^2)\n                        + Pct.drive.wkend + I(Pct.drive.wkend^2)\n                        + max.day + log(max.day) \n                        + min.day + I(min.day^2)\n                        + max.min + I(max.min^2)\n                        + Pct.drive.rush.am + sqrt(Pct.drive.rush.am) \n                        + Pct.drive.rush.pm + sqrt(Pct.drive.rush.pm)   \n                        + Pct.drive.2hrs + sqrt(Pct.drive.2hrs) \n                        + Pct.drive.3hrs + sqrt(Pct.drive.3hrs) \n                        + Pct.drive.4hrs + sqrt(Pct.drive.4hrs) \n                        + Accel.06miles + I(Accel.06miles^2) + I(Accel.06miles^3)\n                        + Accel.08miles + I(Accel.08miles^2) + I(Accel.08miles^3)\n                        + Accel.09miles + I(Accel.09miles^2) + I(Accel.09miles^3)\n                        + Accel.11miles + I(Accel.11miles^2) + I(Accel.11miles^3)\n                        + Accel.12miles + I(Accel.12miles^2) + I(Accel.12miles^3)\n                        + Accel.14miles + I(Accel.14miles^2) + I(Accel.14miles^3)\n                        + Brake.06miles + I(Brake.06miles^2) + I(Brake.06miles^3)\n                        + Brake.08miles + I(Brake.08miles^2) + I(Brake.08miles^3)\n                        + Brake.09miles + I(Brake.09miles^2) + I(Brake.09miles^3)\n                        + Brake.11miles + I(Brake.11miles^2) + I(Brake.11miles^3)\n                        + Brake.12miles + I(Brake.12miles^2) + I(Brake.12miles^3)\n                        + Brake.14miles + I(Brake.14miles^2) + I(Brake.14miles^3)\n                        + Left.turn.intensity08 + log1p(Left.turn.intensity08)\n                        + Left.turn.intensity09 + log1p(Left.turn.intensity09)\n                        + Left.turn.intensity10 + log1p(Left.turn.intensity10)\n                        + Left.turn.intensity11 + log1p(Left.turn.intensity11)\n                        + Left.turn.intensity12 + log1p(Left.turn.intensity12)\n                        + Right.turn.intensity08 + log1p(Right.turn.intensity08)\n                        + Right.turn.intensity09 + log1p(Right.turn.intensity09)\n                        + Right.turn.intensity10 + log1p(Right.turn.intensity10)\n                        + Right.turn.intensity11 + log1p(Right.turn.intensity11)\n                        + Right.turn.intensity12 + log1p(Right.turn.intensity12))\n\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$NB_Claim\noffset <- log(train2$expo)\n\nlambda.min <- 3.981072e-05\nlambda.1se <- 0.001258925\n    \nlambda.select <- lambda.1se\n#fit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\nfit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n  \nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$NB_Claim\noffset <- log(test2$expo)\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('LASSO (parsimonious)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15536 </td>\n   <td style=\"text-align:center;\"> 0.04239 </td>\n   <td style=\"text-align:center;\"> -0.92624 </td>\n   <td style=\"text-align:center;\"> -0.96135 </td>\n   <td style=\"text-align:center;\"> -2.69596 </td>\n   <td style=\"text-align:center;\"> 0.03866 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15704 </td>\n   <td style=\"text-align:center;\"> 0.04261 </td>\n   <td style=\"text-align:center;\"> -0.92579 </td>\n   <td style=\"text-align:center;\"> -0.96120 </td>\n   <td style=\"text-align:center;\"> -2.70016 </td>\n   <td style=\"text-align:center;\"> 0.03889 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### RESIDUALS AND PROTECTED VARIABLES\n\nComparing the results obtained with the pricing model based solely on traditional variables, we observe that the addition of telematic variables improves prediction quality. However, we can verify whether the protected variables we excluded from the analysis still retain predictive capability. Thus, we fit a GLM-net model on telematic data and predict the expected frequency of the model on the training dataset.  \n\nUsing the prediction as an offset variable, we can effectively assess whether the protected variables still capture a trend. The reliability of this approach is further bolstered by the comparison of the results obtained with the graphs we had in Chapter 2. If a curve is horizontal and close to the value of 1 for all possible values of a covariate, it indicates that telematic variables have indeed captured the predictive capability of the variable to predict claim frequency, as demonstrated in the graphs below.\n\nIn the graphs below, we observe that the addition of telematic variables:  \n\n- diminishes the effect of credit score, but it still appears to be predictive;  \n- almost eliminates the effect of driver age;  \n- the addition of telematic variables has led to a significant shift in the effect of driver gender. Originally, a premium reduction for males seemed necessary, but adding telematic variables suggest that males should now have a surcharge;\n- significantly reduces the effect of marital status;  \n- slightly diminishes the effect of territory without eliminating it.\n\n\n::: {#fig-CreditScore_sev .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmeaninv  <- sum(train2$expo)/sum(train2$NB_Claim)\n\ntemp2 <- train2 %>%\n  dplyr::mutate(Duration.y = Duration/365.25, \n                Insured.age = pmin(Insured.age, 80),\n                Group = ceiling(Credit.score/25) * 25) %>%\n  group_by(Group) %>% \n  summarize(NB_Claim=sum(NB_Claim),\n            expo=sum(expo),\n            expo2=sum(pred.tele)) %>% \n  mutate(freq = meaninv*NB_Claim/expo, \n         freq2 =  NB_Claim/expo2)\n\nggplot() + \n  geom_smooth(aes(x=Group, y=freq, weight = expo, color='Observed'),se=F, size=1, data=temp2) + \n  geom_smooth(aes(x=Group, y=freq2, weight = expo, color='Residuals'),se=F, size=1, data=temp2) + \n  labs(x = 'Credit Score',\n       y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  guides(color = guide_legend(title = \"\")) +\n      theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n### Age of the insured\n\ntemp2 <- train2 %>%\n  dplyr::mutate(Duration.y = Duration/365.25, \n                Insured.age = pmin(Insured.age, 80),\n                Group = ceiling(Insured.age/5) * 5) %>%\n  group_by(Group) %>% \n  summarize(NB_Claim=sum(NB_Claim),\n            expo=sum(expo),\n            expo2=sum(pred.tele)) %>% \n  mutate(freq = meaninv*NB_Claim/expo, \n         freq2 =  NB_Claim/expo2)\n\nggplot() + \n  geom_smooth(aes(x=Group, y=freq, weight = expo, color='Observed'),se=F, size=1, data=temp2) + \n  geom_smooth(aes(x=Group, y=freq2, weight = expo, color='Residuals'),se=F, size=1, data=temp2) + \n  labs(x = 'Age of the insured',\n       y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  guides(color = guide_legend(title = \"\")) +\n        theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n### Sex of the insured\n\ntemp <- train2 %>%\n  mutate(Var_ = Insured.sex) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.tele)) %>%\n  mutate(freq = nbclaim/expo,\n         freq2 = nbclaim/expo2)\n\ntemp$freq <- temp$freq/temp$freq[1]\ntemp$freq2 <- temp$freq2/temp$freq2[1]\n\nggplot() + #start plot by by plotting bars\n  geom_point(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=0.7) +\n  labs(x = 'Sex of the insured', y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  ylim(max(temp$freq, temp$freq2)*0.95, max(temp$freq, temp$freq2)*1.05)+\n  guides(color=guide_legend(title=\"\")) +\n      theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n### Marital Status\n\ntemp <- train2 %>%\n  mutate(Var_ = Marital) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.tele)) %>%\n  mutate(freq = nbclaim/expo, \n         freq2 = nbclaim/expo2)\n\ntemp$freq <- temp$freq/temp$freq[1]\ntemp$freq2 <- temp$freq2/temp$freq2[1]\n\nggplot() + #start plot by by plotting bars\n  geom_point(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=0.7) +\n  labs(x = 'Marital status of the insured', y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  ylim(0.9, max(temp$freq, temp$freq2)*1.2)+\n  guides(color=guide_legend(title=\"\")) +\n      theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n### Insured's territory\n\ntemp <- train2 %>%\n  mutate(Var_ = Territory) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.tele)) %>%\n  mutate(freq1 = nbclaim/expo2, \n         freq2 = meaninv*nbclaim/expo)\n\nggplot() + \n  geom_line(data = temp, aes(x = Var_, y = freq1, group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = freq1, group = 1, color='Residuals'), size=0.7) +\n  geom_line(data = temp, aes(x = Var_, y = freq2, group = 1, color='Observed'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = freq2, group = 1, color='Observed'), size=0.7) +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  labs(x = 'Territory',\n       y = 'Relativity') +\n  scale_x_discrete(labels = NULL, breaks = NULL)+\n  guides(color=guide_legend(title=\"\")) +\n      theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n```\n\n::: {.cell-output-display}\n![Credit Score](VarTelematiques_files/figure-html/fig-CreditScore_sev-1.png){#fig-CreditScore_sev-1 width=864}\n:::\n\n::: {.cell-output-display}\n![Age of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev-2.png){#fig-CreditScore_sev-2 width=864}\n:::\n\n::: {.cell-output-display}\n![Sex of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev-3.png){#fig-CreditScore_sev-3 width=864}\n:::\n\n::: {.cell-output-display}\n![Marital Status of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev-4.png){#fig-CreditScore_sev-4 width=864}\n:::\n\n::: {.cell-output-display}\n![Territory](VarTelematiques_files/figure-html/fig-CreditScore_sev-5.png){#fig-CreditScore_sev-5 width=864}\n:::\n\nObserved Relativity vs. Residuals Relativity\n:::\n\n\n### GLM-NET ON RESIDUALS\n\nOne can directly fit a GLM-Net model by appropriately utilizing the initial predictions. By retaining only the protected variables in the GLM-Net approach while using the prediction as an offset variable, it is possible to verify whether adding protected variables enhances the model's predictive capacity.  \n\nThe tables below indicate the scores obtained for this new model (with the two approaches marked with an *). We observe a slight improvement in the model, indicating that using telematics data does not eliminate the need to use protected variables.\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-Pscore_basetest4b .cell tbl-cap='Prediction scores for the GLM-net model  (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(NB_Claim ~ Car.use + Region + Car.age + I(Car.age^2) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3)\n                        + Dayformax + Dayformin +\n                        + Miles.per.day + log(Miles.per.day)\n                        + Avgdays.week + I(Avgdays.week^2)\n                        + Pct.drive.mon + I(Pct.drive.mon^2)\n                        + Pct.drive.tue + I(Pct.drive.tue^2)\n                        + Pct.drive.wed + I(Pct.drive.wed^2)\n                        + Pct.drive.thr + I(Pct.drive.thr^2)\n                        + Pct.drive.fri + I(Pct.drive.fri^2)\n                        + Pct.drive.sat + I(Pct.drive.sat^2)\n                        + Pct.drive.sun + I(Pct.drive.sun^2)\n                        + Pct.drive.wkend + I(Pct.drive.wkend^2)\n                        + max.day + log(max.day) \n                        + min.day + I(min.day^2)\n                        + max.min + I(max.min^2)\n                        + Pct.drive.rush.am + sqrt(Pct.drive.rush.am) \n                        + Pct.drive.rush.pm + sqrt(Pct.drive.rush.pm)   \n                        + Pct.drive.2hrs + sqrt(Pct.drive.2hrs) \n                        + Pct.drive.3hrs + sqrt(Pct.drive.3hrs) \n                        + Pct.drive.4hrs + sqrt(Pct.drive.4hrs) \n                        + Accel.06miles + I(Accel.06miles^2) + I(Accel.06miles^3)\n                        + Accel.08miles + I(Accel.08miles^2) + I(Accel.08miles^3)\n                        + Accel.09miles + I(Accel.09miles^2) + I(Accel.09miles^3)\n                        + Accel.11miles + I(Accel.11miles^2) + I(Accel.11miles^3)\n                        + Accel.12miles + I(Accel.12miles^2) + I(Accel.12miles^3)\n                        + Accel.14miles + I(Accel.14miles^2) + I(Accel.14miles^3)\n                        + Brake.06miles + I(Brake.06miles^2) + I(Brake.06miles^3)\n                        + Brake.08miles + I(Brake.08miles^2) + I(Brake.08miles^3)\n                        + Brake.09miles + I(Brake.09miles^2) + I(Brake.09miles^3)\n                        + Brake.11miles + I(Brake.11miles^2) + I(Brake.11miles^3)\n                        + Brake.12miles + I(Brake.12miles^2) + I(Brake.12miles^3)\n                        + Brake.14miles + I(Brake.14miles^2) + I(Brake.14miles^3)\n                        + Left.turn.intensity08 + log1p(Left.turn.intensity08)\n                        + Left.turn.intensity09 + log1p(Left.turn.intensity09)\n                        + Left.turn.intensity10 + log1p(Left.turn.intensity10)\n                        + Left.turn.intensity11 + log1p(Left.turn.intensity11)\n                        + Left.turn.intensity12 + log1p(Left.turn.intensity12)\n                        + Right.turn.intensity08 + log1p(Right.turn.intensity08)\n                        + Right.turn.intensity09 + log1p(Right.turn.intensity09)\n                        + Right.turn.intensity10 + log1p(Right.turn.intensity10)\n                        + Right.turn.intensity11 + log1p(Right.turn.intensity11)\n                        + Right.turn.intensity12 + log1p(Right.turn.intensity12))\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$NB_Claim\noffset <- log(train2$expo)\n    \nlambda.min <- 3.981072e-05\nlasso.min <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.min)\ntrain2$pred.tele <- predict(lasso.min, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.min)\n\nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$NB_Claim\noffset <- log(test2$expo)\ntest2$pred.tele <- predict(lasso.min, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.min)\n\nglm.score <- as.formula(NB_Claim ~ Insured.sex + Marital \n                                  + Credit.score +  I(Credit.score^2) \n                                  + Insured.age +  log(Insured.age) + I(Insured.age^2) \n                                  + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$NB_Claim\noffset <- log(train2$pred.tele)\n\nlambda.min <- 1e-08\nlambda.1se <- 0.007943282\n    \nlambda.select <- lambda.min\n#fit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\nfit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n  \nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$NB_Claim\noffset <- log(test2$pred.tele)\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('LASSO* (optimal)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\n###\n\nglm.score <- as.formula(NB_Claim ~ Insured.sex + Marital \n                                  + Credit.score +  I(Credit.score^2) \n                                  + Insured.age +  log(Insured.age) + I(Insured.age^2) \n                                  + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$NB_Claim\noffset <- log(train2$pred.tele)\n\nlambda.min <- 1e-08\nlambda.1se <- 0.007943282\n    \nlambda.select <- lambda.1se\nfit <- glmnet(matrix.x, y, family = \"poisson\", relax=FALSE, offset = offset, alpha = 1, lambda = lambda.select)\n#fit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 1, lambda = lambda.select)\n  \nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$NB_Claim\noffset <- log(test2$pred.tele)\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', newoffset=offset, lambda = lambda.select)\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('LASSO* (parsimonious)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15536 </td>\n   <td style=\"text-align:center;\"> 0.04239 </td>\n   <td style=\"text-align:center;\"> -0.92624 </td>\n   <td style=\"text-align:center;\"> -0.96135 </td>\n   <td style=\"text-align:center;\"> -2.69596 </td>\n   <td style=\"text-align:center;\"> 0.03866 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15704 </td>\n   <td style=\"text-align:center;\"> 0.04261 </td>\n   <td style=\"text-align:center;\"> -0.92579 </td>\n   <td style=\"text-align:center;\"> -0.96120 </td>\n   <td style=\"text-align:center;\"> -2.70016 </td>\n   <td style=\"text-align:center;\"> 0.03889 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15373 </td>\n   <td style=\"text-align:center;\"> 0.04209 </td>\n   <td style=\"text-align:center;\"> -0.92677 </td>\n   <td style=\"text-align:center;\"> -0.96154 </td>\n   <td style=\"text-align:center;\"> -2.62254 </td>\n   <td style=\"text-align:center;\"> 0.03837 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15481 </td>\n   <td style=\"text-align:center;\"> 0.04226 </td>\n   <td style=\"text-align:center;\"> -0.92642 </td>\n   <td style=\"text-align:center;\"> -0.96142 </td>\n   <td style=\"text-align:center;\"> -2.69780 </td>\n   <td style=\"text-align:center;\"> 0.03855 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n:::\n\n## XGBoost\n\nWe now consider an XGBoost model. As with the frequency model, hyperparameter values are obtained by performing a Bayesian search on a grid of possible values.\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.panel-tabset}\n\n### Prediction Scores\n\nWe can calculate the models prediction scores based on all classical and telematics covariates. The XGBoost approach is particularly effective in capturing the effect of all available telematic covariates. Indeed, the scores obtained are significantly improved compared to other tested approaches.\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-Pscore_XGBoosttele .cell tbl-cap='Prediction scores for the XGBoost model with telematics'}\n\n```{.r .cell-code  code-fold=\"true\"}\nparam <- list(\n  eta = 0.02337437,\n  max_depth = 26,\n  subsample = 0.8097923,\n  min_child_weight = 1,\n  booster = \"gbtree\",\n  objective = \"count:poisson\",\n  eval_metric = \"poisson-nloglik\")\n\nset.seed(133)\nxgbcv <- xgb.cv(params = param,\n                nrounds = 367,\n                data = dtrain,\n                folds = folds,\n                prediction = TRUE,\n                early_stopping_rounds = 10,\n                verbose = 0,\n                maximize = F)\n  \nSc.log <- sapply(xgbcv$folds, function(x){-dpois(train2$NB_Claim[x], unlist(xgbcv$pred[x]), log=TRUE)})\nSc.MSE <- sapply(xgbcv$folds, function(x){(train2$NB_Claim[x]-unlist(xgbcv$pred[x]))^2})\nSc.quad <- sapply(xgbcv$folds, function(x){\n  nb <- train2$NB_Claim[x]\n  mu <- unlist(xgbcv$pred[x])\n  -2*dpois(nb,lambda=mu) + dpois(0,lambda=mu)^2 + dpois(1,lambda=mu)^2 + dpois(2,lambda=mu)^2+ dpois(3,lambda=mu)^2 + dpois(4,lambda=mu)^2 + dpois(5,lambda=mu)^2 \n})  \nSc.sph <- sapply(xgbcv$folds, function(x){\n  nb <- train2$NB_Claim[x]\n  mu <- unlist(xgbcv$pred[x])\n  -dpois(nb,lambda=mu) / sqrt(dpois(0,lambda=mu)^2 + dpois(1,lambda=mu)^2 + dpois(2,lambda=mu)^2+ dpois(3,lambda=mu)^2 + dpois(4,lambda=mu)^2 + dpois(5,lambda=mu)^2 ) \n})\nSc.DSS <- sapply(xgbcv$folds, function(x){dss_pois(train2$NB_Claim[x], unlist(xgbcv$pred[x]))})\nSc.CRPS <- sapply(xgbcv$folds, function(x){crps_pois(train2$NB_Claim[x], unlist(xgbcv$pred[x]))})\n\nResult_  <- rbind(\nc(1,mean(Sc.log[1]$fold1), mean(Sc.MSE[1]$fold1), mean(Sc.quad[1]$fold1), mean(Sc.sph[1]$fold1), mean(Sc.DSS[1]$fold1), mean(Sc.CRPS[1]$fold1)),\nc(2,mean(Sc.log[2]$fold2), mean(Sc.MSE[2]$fold2), mean(Sc.quad[2]$fold2), mean(Sc.sph[2]$fold2), mean(Sc.DSS[2]$fold2), mean(Sc.CRPS[2]$fold2)),\nc(3,mean(Sc.log[3]$fold3), mean(Sc.MSE[3]$fold3), mean(Sc.quad[3]$fold3), mean(Sc.sph[3]$fold3), mean(Sc.DSS[3]$fold3), mean(Sc.CRPS[3]$fold3)),\nc(4,mean(Sc.log[4]$fold4), mean(Sc.MSE[4]$fold4), mean(Sc.quad[4]$fold4), mean(Sc.sph[4]$fold4), mean(Sc.DSS[4]$fold4), mean(Sc.CRPS[4]$fold4)),\nc(5,mean(Sc.log[5]$fold5), mean(Sc.MSE[5]$fold5), mean(Sc.quad[5]$fold5), mean(Sc.sph[5]$fold5), mean(Sc.DSS[5]$fold5), mean(Sc.CRPS[5]$fold5))\n)\n\nRes.sum  <- rbind(\nc(sum(Sc.log[1]$fold1), sum(Sc.MSE[1]$fold1), sum(Sc.quad[1]$fold1), sum(Sc.sph[1]$fold1), sum(Sc.DSS[1]$fold1), sum(Sc.CRPS[1]$fold1)),\nc(sum(Sc.log[2]$fold2), sum(Sc.MSE[2]$fold2), sum(Sc.quad[2]$fold2), sum(Sc.sph[2]$fold2), sum(Sc.DSS[2]$fold2), sum(Sc.CRPS[2]$fold2)),\nc(sum(Sc.log[3]$fold3), sum(Sc.MSE[3]$fold3), sum(Sc.quad[3]$fold3), sum(Sc.sph[3]$fold3), sum(Sc.DSS[3]$fold3), sum(Sc.CRPS[3]$fold3)),\nc(sum(Sc.log[4]$fold4), sum(Sc.MSE[4]$fold4), sum(Sc.quad[4]$fold4), sum(Sc.sph[4]$fold4), sum(Sc.DSS[4]$fold4), sum(Sc.CRPS[4]$fold4)),\nc(sum(Sc.log[5]$fold5), sum(Sc.MSE[5]$fold5), sum(Sc.quad[5]$fold5), sum(Sc.sph[5]$fold5), sum(Sc.DSS[5]$fold5), sum(Sc.CRPS[5]$fold5))\n)\nsum <- c('Total', colSums(Res.sum)/nrow(train2))\n\nResult_  <- data.frame(rbind(Result_, sum)) \n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:7){\n  Result_[,i] <- as.numeric(Result_[,i])  \n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.13388 </td>\n   <td style=\"text-align:center;\"> 0.03521 </td>\n   <td style=\"text-align:center;\"> -0.93284 </td>\n   <td style=\"text-align:center;\"> -0.96351 </td>\n   <td style=\"text-align:center;\"> -3.06883 </td>\n   <td style=\"text-align:center;\"> 0.03421 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0.12792 </td>\n   <td style=\"text-align:center;\"> 0.03257 </td>\n   <td style=\"text-align:center;\"> -0.93583 </td>\n   <td style=\"text-align:center;\"> -0.96499 </td>\n   <td style=\"text-align:center;\"> -3.15351 </td>\n   <td style=\"text-align:center;\"> 0.03241 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 0.12411 </td>\n   <td style=\"text-align:center;\"> 0.03254 </td>\n   <td style=\"text-align:center;\"> -0.93948 </td>\n   <td style=\"text-align:center;\"> -0.96697 </td>\n   <td style=\"text-align:center;\"> -3.12854 </td>\n   <td style=\"text-align:center;\"> 0.03113 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 0.14126 </td>\n   <td style=\"text-align:center;\"> 0.03757 </td>\n   <td style=\"text-align:center;\"> -0.92850 </td>\n   <td style=\"text-align:center;\"> -0.96108 </td>\n   <td style=\"text-align:center;\"> -3.03608 </td>\n   <td style=\"text-align:center;\"> 0.03648 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0.13492 </td>\n   <td style=\"text-align:center;\"> 0.03562 </td>\n   <td style=\"text-align:center;\"> -0.93262 </td>\n   <td style=\"text-align:center;\"> -0.96335 </td>\n   <td style=\"text-align:center;\"> -3.05897 </td>\n   <td style=\"text-align:center;\"> 0.03442 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 0.13241 </td>\n   <td style=\"text-align:center;\"> 0.03470 </td>\n   <td style=\"text-align:center;\"> -0.93386 </td>\n   <td style=\"text-align:center;\"> -0.96398 </td>\n   <td style=\"text-align:center;\"> -3.08921 </td>\n   <td style=\"text-align:center;\"> 0.03373 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.05138 </td>\n   <td style=\"text-align:center;\"> -0.01306 </td>\n   <td style=\"text-align:center;\"> -0.01611 </td>\n   <td style=\"text-align:center;\"> -0.00611 </td>\n   <td style=\"text-align:center;\"> -0.95232 </td>\n   <td style=\"text-align:center;\"> -0.00954 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOn the *test* set, we obtain:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndtrain <- xgb.DMatrix(data = data.matrix(train2[, paste(all.vars2)]), label = train2$NB_Claim)\nsetinfo(dtrain,\"base_margin\",log(train2$expo))\ndtest <- xgb.DMatrix(data = data.matrix(test2[, paste(all.vars2)]), label = test2$NB_Claim)\nsetinfo(dtest,\"base_margin\",log(test2$expo))\nfolds <-list(fold1 = which(train2$fold == 1),\n             fold2 = which(train2$fold == 2),\n             fold3 = which(train2$fold == 3),\n             fold4 = which(train2$fold == 4),\n             fold5 = which(train2$fold == 5))\n```\n:::\n\n::: {#tbl-Pscore_XGBoost_correction333 .cell tbl-cap='Prediction scores for the XGBoost model with telematics'}\n\n```{.r .cell-code  code-fold=\"true\"}\nparam <- list(\n  eta = 0.02337437,\n  max_depth = 26,\n  subsample = 0.8097923,\n  min_child_weight = 1,\n  booster = \"gbtree\",\n  objective = \"count:poisson\",\n  eval_metric = \"poisson-nloglik\")\n\nset.seed(133)\nfit.xgb <- xgb.train(params = param,\n                     nrounds = 367,\n                     data = dtrain)\n\ntrain2$pred.xgb <- predict(fit.xgb, dtrain, type='response')\n\n\ntest2$pred.xgb <- predict(fit.xgb, dtest, type='response')\n\ntest2$pred.base <- test2$pred.xgb\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('XGBoost', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15536 </td>\n   <td style=\"text-align:center;\"> 0.04239 </td>\n   <td style=\"text-align:center;\"> -0.92624 </td>\n   <td style=\"text-align:center;\"> -0.96135 </td>\n   <td style=\"text-align:center;\"> -2.69596 </td>\n   <td style=\"text-align:center;\"> 0.03866 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15704 </td>\n   <td style=\"text-align:center;\"> 0.04261 </td>\n   <td style=\"text-align:center;\"> -0.92579 </td>\n   <td style=\"text-align:center;\"> -0.96120 </td>\n   <td style=\"text-align:center;\"> -2.70016 </td>\n   <td style=\"text-align:center;\"> 0.03889 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15373 </td>\n   <td style=\"text-align:center;\"> 0.04209 </td>\n   <td style=\"text-align:center;\"> -0.92677 </td>\n   <td style=\"text-align:center;\"> -0.96154 </td>\n   <td style=\"text-align:center;\"> -2.62254 </td>\n   <td style=\"text-align:center;\"> 0.03837 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15481 </td>\n   <td style=\"text-align:center;\"> 0.04226 </td>\n   <td style=\"text-align:center;\"> -0.92642 </td>\n   <td style=\"text-align:center;\"> -0.96142 </td>\n   <td style=\"text-align:center;\"> -2.69780 </td>\n   <td style=\"text-align:center;\"> 0.03855 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> XGBoost </td>\n   <td style=\"text-align:center;\"> 0.12142 </td>\n   <td style=\"text-align:center;\"> 0.03110 </td>\n   <td style=\"text-align:center;\"> -0.93907 </td>\n   <td style=\"text-align:center;\"> -0.96656 </td>\n   <td style=\"text-align:center;\"> -3.21523 </td>\n   <td style=\"text-align:center;\"> 0.03081 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Variables Importance\n\nThe graph below illustrates the most critical variables in the XGBoost model for claim frequency. As indicated in the literature, the level of vehicle usage, represented here by the daily mileage, is the most crucial variable in the model. Driving experience, measured by the number of claim-free years, follows. To a lesser extent, a series of telematic variables also has predictive capability.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nimportance_matrix <- xgb.importance(dimnames(dtrain)[[2]], model = fit.xgb)\nxgb.ggplot.importance(importance_matrix,top_n=15) + theme(text = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](VarTelematiques_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n### RESIDUALS AND PROTECTED VARIABLES\n\nAs we did for the GLM-Net approach, we can again analyze the residuals of the approach to see if the addition of telematic data eliminates the need to use protected variables. The graphs below show that XGBoost is even more effective than GLM-Net. Indeed, although the credit score still appears useful in modeling frequency, its effect is greatly diminished. The effects of age, gender, and marital status of the insured are also significantly reduced. Finally, we can even see that the effect of territory is also greatly minimized.\n\n\n\n::: {#fig-CreditScore_sev2 .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmeaninv  <- sum(train2$expo)/sum(train2$NB_Claim)\nmoy.xgb <- sum(train2$pred.xgb)/sum(train2$NB_Claim)\n\ntemp2 <- train2 %>%\n  dplyr::mutate(Duration.y = Duration/365.25, \n                Insured.age = pmin(Insured.age, 80),\n                Group = ceiling(Credit.score/25) * 25) %>%\n  group_by(Group) %>% \n  summarize(NB_Claim=sum(NB_Claim),\n            expo=sum(expo),\n            expo2=sum(pred.xgb)) %>% \n  mutate(freq = meaninv*NB_Claim/expo, \n         freq2 =  moy.xgb*NB_Claim/expo2)\n\nGraph_resCS <- ggplot() + \n  geom_smooth(aes(x=Group, y=freq, weight = expo, color='Observed'),se=F, size=1, data=temp2) + \n  geom_smooth(aes(x=Group, y=freq2, weight = expo, color='Residuals'),se=F, size=1, data=temp2) + \n  labs(x = 'Credit Score',\n       y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  guides(color = guide_legend(title = \"\")) +\n    theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\nprint(Graph_resCS)\nsave(Graph_resCS, file = \"Data/Graph_resCS.rdata\")\n\n### Age of the insured\n\ntemp2 <- train2 %>%\n  dplyr::mutate(Duration.y = Duration/365.25, \n                Insured.age = pmin(Insured.age, 80), \n                Group = ceiling(Insured.age/5) * 5) %>%\n  group_by(Group) %>% \n  summarize(NB_Claim=sum(NB_Claim),\n            expo=sum(expo),\n            expo2=sum(pred.xgb)) %>% \n  mutate(freq = meaninv*NB_Claim/expo, \n         freq2 =  moy.xgb*NB_Claim/expo2)\n\nGraph_resAge <- ggplot() + \n  geom_smooth(aes(x=Group, y=freq, weight = expo, color='Observed'),se=F, size=1, data=temp2) + \n  geom_smooth(aes(x=Group, y=freq2, weight = expo, color='Residuals'),se=F, size=1, data=temp2) + \n  labs(x = 'Age of the insured',\n       y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  guides(color = guide_legend(title = \"\")) +\n    theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\nprint(Graph_resAge)\nsave(Graph_resAge, file = \"Data/Graph_resAge.rdata\")\n\n### Sex of the insured\n\n\ntemp <- train2 %>%\n  mutate(Var_ = Insured.sex) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.xgb)) %>%\n  mutate(freq = nbclaim/expo,\n         freq2 = nbclaim/expo2)\n\ntemp$freq <- temp$freq/temp$freq[1]\ntemp$freq2 <- temp$freq2/temp$freq2[1]\n\nggplot() + #start plot by by plotting bars\n  geom_point(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=0.7) +\n  labs(x = 'Sex of the insured', y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  ylim(max(temp$freq, temp$freq2)*0.95, max(temp$freq, temp$freq2)*1.05)+\n  guides(color=guide_legend(title=\"\")) +\n    theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n\n### Marital Status\n\n\ntemp <- train2 %>%\n  mutate(Var_ = Marital) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.xgb)) %>%\n  mutate(freq = nbclaim/expo, \n         freq2 = nbclaim/expo2)\n\ntemp$freq <- temp$freq/temp$freq[1]\ntemp$freq2 <- temp$freq2/temp$freq2[1]\n\nggplot() + #start plot by by plotting bars\n  geom_point(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq2), group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=3) +\n  geom_line(data = temp, aes(x = Var_, y = (freq), group = 1, color='Observed'), size=0.7) +\n  labs(x = 'Marital status of the insured', y = 'Relativity') +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  ylim(0.9, max(temp$freq, temp$freq2)*1.2)+\n  guides(color=guide_legend(title=\"\")) +\n    theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\n### Insured's territory\n\ntemp <- train2 %>%\n  mutate(Var_ = Territory) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo),\n            expo2 = sum(pred.xgb)) %>%\n  mutate(freq = moy.xgb*nbclaim/expo2)\n\ntemp2 <- train2 %>%\n  mutate(Var_ = Territory) %>%\n  group_by(Var_) %>%\n  summarize(nbclaim = sum(NB_Claim),\n            expo = sum(expo)) %>%\n  mutate(freq = meaninv*nbclaim/expo)\n\nGraph_resTerr <- ggplot() + \n  geom_line(data = temp, aes(x = Var_, y = freq, group = 1, color='Residuals'), size=0.7) +\n  geom_point(data = temp, aes(x = Var_, y = freq, group = 1, color='Residuals'), size=0.7) +\n  geom_line(data = temp2, aes(x = Var_, y = freq, group = 1, color='Observed'), size=0.7) +\n  geom_point(data = temp2, aes(x = Var_, y = freq, group = 1, color='Observed'), size=0.7) +\n  geom_hline(yintercept = 1, linetype='dashed')+\n  labs(x = 'Territory',\n       y = 'Relativity') +\n  scale_x_discrete(labels = NULL, breaks = NULL)+\n  guides(color=guide_legend(title=\"\")) +\n    theme_classic()+    theme(legend.position = 'bottom', legend.direction = \"horizontal\")\n\nprint(Graph_resTerr)\nsave(Graph_resTerr, file = \"Data/Graph_resTerr.rdata\")\n```\n\n::: {.cell-output-display}\n![Credit Score](VarTelematiques_files/figure-html/fig-CreditScore_sev2-1.png){#fig-CreditScore_sev2-1 width=864}\n:::\n\n::: {.cell-output-display}\n![Age of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev2-2.png){#fig-CreditScore_sev2-2 width=864}\n:::\n\n::: {.cell-output-display}\n![Sex of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev2-3.png){#fig-CreditScore_sev2-3 width=864}\n:::\n\n::: {.cell-output-display}\n![Marital Status of the Insured](VarTelematiques_files/figure-html/fig-CreditScore_sev2-4.png){#fig-CreditScore_sev2-4 width=864}\n:::\n\n::: {.cell-output-display}\n![Territory](VarTelematiques_files/figure-html/fig-CreditScore_sev2-5.png){#fig-CreditScore_sev2-5 width=864}\n:::\n\nObserved Relativity vs. Residuals Relativity\n:::\n\n\n\n\n\n### XGBOOST ON RESIDUALS\n\nWe repeat the same exercise we did with the GLM-Net approach: fitting an XGBoost model on the residuals of the first XGBoost model. This will allow us to see if protected variables are capable of capturing trends in the approach's residuals.\n\nThe table below shows the different scores for the XGBoost* model. There is only a gain on some of the indicated scores. Hence, telematics data can substitute protected variables based on the studied dataset.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(xgboost)\nlibrary(Ckmeans.1d.dp)\nlibrary(SHAPforxgboost)\nlibrary(pacman)\n\nvar.sens <- c(\"Marital\", \"Insured.sex\", \"Credit.score\", \"Insured.age\", \"Territory\")    \n\ndtrain <- xgb.DMatrix(data = data.matrix(train2[, paste(var.sens)]), label = train2$NB_Claim)\nsetinfo(dtrain,\"base_margin\",log(train2$pred.xgb))\nfolds <-list(fold1 = which(train2$fold == 1),\n             fold2 = which(train2$fold == 2),\n             fold3 = which(train2$fold == 3),\n             fold4 = which(train2$fold == 4),\n             fold5 = which(train2$fold == 5))\n\nparam <- list(\n  eta = 0.2215803,\n  max_depth = 50,\n  subsample = 0.7623535,\n  min_child_weight = 1,\n  booster = \"gbtree\",\n  objective = \"count:poisson\",\n  eval_metric = \"poisson-nloglik\")\n\nset.seed(533)\nfit.xgb2 <- xgb.train(params = param,\n                      nrounds = 5,\n                      data = dtrain)\n\ndtest <- xgb.DMatrix(data = data.matrix(test2[, paste(var.sens)]), label = test2$NB_Claim)\nsetinfo(dtest,\"base_margin\",log(test2$pred.xgb))\n```\n:::\n\n::: {#tbl-Pscore_XGBoost_correction33 .cell tbl-cap='Prediction scores for the XGBoost model with telematics'}\n\n```{.r .cell-code  code-fold=\"true\"}\ntest2$pred.base <- predict(fit.xgb2, dtest, type='response')\n\nResult_ <- data.frame(t(Score.pred(test2$pred.base, test2$NB_Claim)/nrow(test2)))\nResult_ <- cbind('XGBoost*', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\", \"Sc.quad\", \"Sc.sph\", \"Sc.DSS\", \"Sc.CRPS\")\n\nResult_all <- rbind(Result_all, Result_)\n\nsave(Result_all, file='Data/ResultsSynth.Rda')\n\nknitr::kable(Result_all, align = \"ccccccc\", digits = c(0, 5, 5, 5, 5, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = T)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n   <th style=\"text-align:center;\"> Sc.quad </th>\n   <th style=\"text-align:center;\"> Sc.sph </th>\n   <th style=\"text-align:center;\"> Sc.DSS </th>\n   <th style=\"text-align:center;\"> Sc.CRPS </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 0.17674 </td>\n   <td style=\"text-align:center;\"> 0.04545 </td>\n   <td style=\"text-align:center;\"> -0.92147 </td>\n   <td style=\"text-align:center;\"> -0.95981 </td>\n   <td style=\"text-align:center;\"> -2.19876 </td>\n   <td style=\"text-align:center;\"> 0.04127 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 0.17359 </td>\n   <td style=\"text-align:center;\"> 0.04514 </td>\n   <td style=\"text-align:center;\"> -0.92197 </td>\n   <td style=\"text-align:center;\"> -0.95995 </td>\n   <td style=\"text-align:center;\"> -2.27716 </td>\n   <td style=\"text-align:center;\"> 0.04099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15536 </td>\n   <td style=\"text-align:center;\"> 0.04239 </td>\n   <td style=\"text-align:center;\"> -0.92624 </td>\n   <td style=\"text-align:center;\"> -0.96135 </td>\n   <td style=\"text-align:center;\"> -2.69596 </td>\n   <td style=\"text-align:center;\"> 0.03866 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15704 </td>\n   <td style=\"text-align:center;\"> 0.04261 </td>\n   <td style=\"text-align:center;\"> -0.92579 </td>\n   <td style=\"text-align:center;\"> -0.96120 </td>\n   <td style=\"text-align:center;\"> -2.70016 </td>\n   <td style=\"text-align:center;\"> 0.03889 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (optimal) </td>\n   <td style=\"text-align:center;\"> 0.15373 </td>\n   <td style=\"text-align:center;\"> 0.04209 </td>\n   <td style=\"text-align:center;\"> -0.92677 </td>\n   <td style=\"text-align:center;\"> -0.96154 </td>\n   <td style=\"text-align:center;\"> -2.62254 </td>\n   <td style=\"text-align:center;\"> 0.03837 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO* (parsimonious) </td>\n   <td style=\"text-align:center;\"> 0.15481 </td>\n   <td style=\"text-align:center;\"> 0.04226 </td>\n   <td style=\"text-align:center;\"> -0.92642 </td>\n   <td style=\"text-align:center;\"> -0.96142 </td>\n   <td style=\"text-align:center;\"> -2.69780 </td>\n   <td style=\"text-align:center;\"> 0.03855 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> XGBoost </td>\n   <td style=\"text-align:center;\"> 0.12142 </td>\n   <td style=\"text-align:center;\"> 0.03110 </td>\n   <td style=\"text-align:center;\"> -0.93907 </td>\n   <td style=\"text-align:center;\"> -0.96656 </td>\n   <td style=\"text-align:center;\"> -3.21523 </td>\n   <td style=\"text-align:center;\"> 0.03081 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> XGBoost* </td>\n   <td style=\"text-align:center;\"> 0.12373 </td>\n   <td style=\"text-align:center;\"> 0.03250 </td>\n   <td style=\"text-align:center;\"> -0.93737 </td>\n   <td style=\"text-align:center;\"> -0.96579 </td>\n   <td style=\"text-align:center;\"> -3.29489 </td>\n   <td style=\"text-align:center;\"> 0.03181 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAlthough the XGBoost model on residuals does not yield significant gains, the graph below illustrates the most critical protected variables in the XGBoost model. It shows that the insured's credit score and territory are the most critical variables in this model.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nimportance_matrix <- xgb.importance(dimnames(dtrain)[[2]], model = fit.xgb2)\nxgb.ggplot.importance(importance_matrix,top_n=15) + theme(text = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](VarTelematiques_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\n\n\n\n",
    "supporting": [
      "VarTelematiques_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}