{
  "hash": "77cd41b8f3116ea33607af70cde033f7",
  "result": {
    "markdown": "# Traditional Covariates\n\n## Preamble\n\n::: {.panel-tabset}\n\n### Chapter Objective\n\nUsing only traditional covariates, the objective of this chapter is to propose various statistical models for estimation and variable selection to predict the number of claims. More specifically, the following model families will be examined:  \n\n- Basic GLM,  \n- GLM family, including elastic-net,    \n- XGBoost.  \n\nAs mentioned in the theory review chapter, to compare models and strike a balance between bias and variance while avoiding overfitting, an interesting approach is to assess the prediction quality of models when applied to new data. The following R script presents a function for calculating various scores:\n\nTo analyze severities, we define two scores:   \n\n1) the negative loglikelihood based on the Gamma distribution with shape parameter = 1/phi and scale = (mu)(phi), where mu is the expected value and phi is the dispersion parameter;   \n2) the mean squared error (MSE) divided by 1,000,000.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nScore.pred.sev <- function(mu, x, phi) {\n  Sc.log  <- -sum(dgamma(x, shape = 1/phi, scale = mu*phi, log=TRUE))\n  Sc.MSE  <- sum((x - mu)^2)/1000000\n  return(c(Sc.log, Sc.MSE))\n}\n```\n:::\n\n\n\n\n### Packages\n\nThe analyses in this chapter will be conducted using the same data as in the previous chapter. Here is the list of packages that will be used:\n  \n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(vtable)\nlibrary(rpart)\nlibrary(repr)\nlibrary(rpart.plot)\n#library(rfCountData)\nlibrary(gam)\nlibrary(sjPlot)\nlibrary(glmnet)\n```\n:::\n\n\n### Data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndataS <- read.csv('Data/Synthetic.csv')\n#dataS <- read.csv(\"~/Library/CloudStorage/Dropbox/AquiLoss/CAS/Telematics/telematics_syn-032021.csv\")\n\ndata <- dataS[dataS$AMT_Claim > 0,]\ndata$M_Claim <- data$AMT_Claim/data$NB_Claim\n\n# Modifications \ndata <- data %>%\n  mutate(Territory = as.factor(Territory)) %>%\n  select(-c('Annual.pct.driven', 'Annual.miles.drive'))\n\ndata.select <- data\n\n# Train-test et folds\nset.seed(123)\ntrain <- data.select %>% sample_frac(0.8, replace = FALSE)\ntest <- data.select %>% anti_join(train)\ntest <- test[-640,]\n\ntrain2 <- train %>%\n  mutate(Miles.per.day = Total.miles.driven/Duration,\n         max.day = pmax(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         min.day = pmin(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         max.min = max.day - min.day,\n         Dayformax = 'Monday', \n         Dayformax = ifelse(max.day == Pct.drive.tue, 'Tuesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.wed, 'Wednesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.thr, 'Thursday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.fri, 'Friday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sat, 'Saturday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sun, 'Sunday', Dayformax),\n         Dayformin = 'Monday', \n         Dayformin = ifelse(min.day == Pct.drive.tue, 'Tuesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.wed, 'Wednesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.thr, 'Thursday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.fri, 'Friday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sat, 'Saturday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sun, 'Sunday', Dayformin),\n         expo = Duration/365.25)\n\ntransform.fct <- function(var){\n  df <- train2 %>% mutate(var_ = get(var)*Total.miles.driven/(1000*Duration))\n  q99 <- quantile(df$var_, 0.99)\n  df <- df %>% mutate(var_ = ifelse(var_ > q99, q99, var_))\n  #colnames(df)[ncol(df)] <- paste0(var, '_')\n  return(df)\n}\n\ntrain2 <- transform.fct(\"Brake.06miles\")\ntrain2 <- transform.fct(\"Brake.08miles\")\ntrain2 <- transform.fct(\"Brake.09miles\")\ntrain2 <- transform.fct(\"Brake.11miles\")\ntrain2 <- transform.fct(\"Brake.14miles\")\ntrain2 <- transform.fct(\"Accel.06miles\")\ntrain2 <- transform.fct(\"Accel.08miles\")\ntrain2 <- transform.fct(\"Accel.09miles\")\ntrain2 <- transform.fct(\"Accel.11miles\")\ntrain2 <- transform.fct(\"Accel.12miles\")\ntrain2 <- transform.fct(\"Accel.14miles\")\ntrain2 <- transform.fct(\"Left.turn.intensity08\")\ntrain2 <- transform.fct(\"Left.turn.intensity09\")\ntrain2 <- transform.fct(\"Left.turn.intensity10\")\ntrain2 <- transform.fct(\"Left.turn.intensity11\")\ntrain2 <- transform.fct(\"Left.turn.intensity12\")\ntrain2 <- transform.fct(\"Right.turn.intensity08\")\ntrain2 <- transform.fct(\"Right.turn.intensity09\")\ntrain2 <- transform.fct(\"Right.turn.intensity10\")\ntrain2 <- transform.fct(\"Right.turn.intensity11\")\ntrain2 <- transform.fct(\"Right.turn.intensity12\")\n\n# Create folds\nnb.fold <- 5\nfold <- sample(1:nb.fold, nrow(train2), replace = TRUE)\ntrain2$fold <- fold\n\n##\n\ntest2 <- test %>%\n  mutate(Miles.per.day = Total.miles.driven/Duration,\n         max.day = pmax(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         min.day = pmin(Pct.drive.mon, Pct.drive.tue, Pct.drive.wed, Pct.drive.thr, Pct.drive.fri, Pct.drive.sat, Pct.drive.sun),\n         max.min = max.day - min.day,\n         Dayformax = 'Monday', \n         Dayformax = ifelse(max.day == Pct.drive.tue, 'Tuesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.wed, 'Wednesday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.thr, 'Thursday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.fri, 'Friday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sat, 'Saturday', Dayformax),\n         Dayformax = ifelse(max.day == Pct.drive.sun, 'Sunday', Dayformax),\n         Dayformin = 'Monday', \n         Dayformin = ifelse(min.day == Pct.drive.tue, 'Tuesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.wed, 'Wednesday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.thr, 'Thursday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.fri, 'Friday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sat, 'Saturday', Dayformin),\n         Dayformin = ifelse(min.day == Pct.drive.sun, 'Sunday', Dayformin),\n         expo = Duration/365.25)\n\ntransform.fct <- function(var){\n  df <- test2 %>% mutate(var_ = get(var)*Total.miles.driven/(1000*Duration))\n  q99 <- quantile(df$var_, 0.99)\n  df <- df %>% mutate(var_ = ifelse(var_ > q99, q99, var_))\n  #colnames(df)[ncol(df)] <- paste0(var, '_')\n  return(df)\n}\n\ntest2 <- transform.fct(\"Brake.06miles\")\ntest2 <- transform.fct(\"Brake.08miles\")\ntest2 <- transform.fct(\"Brake.09miles\")\ntest2 <- transform.fct(\"Brake.11miles\")\ntest2 <- transform.fct(\"Brake.14miles\")\ntest2 <- transform.fct(\"Accel.06miles\")\ntest2 <- transform.fct(\"Accel.08miles\")\ntest2 <- transform.fct(\"Accel.09miles\")\ntest2 <- transform.fct(\"Accel.11miles\")\ntest2 <- transform.fct(\"Accel.12miles\")\ntest2 <- transform.fct(\"Accel.14miles\")\ntest2 <- transform.fct(\"Left.turn.intensity08\")\ntest2 <- transform.fct(\"Left.turn.intensity09\")\ntest2 <- transform.fct(\"Left.turn.intensity10\")\ntest2 <- transform.fct(\"Left.turn.intensity11\")\ntest2 <- transform.fct(\"Left.turn.intensity12\")\ntest2 <- transform.fct(\"Right.turn.intensity08\")\ntest2 <- transform.fct(\"Right.turn.intensity09\")\ntest2 <- transform.fct(\"Right.turn.intensity10\")\ntest2 <- transform.fct(\"Right.turn.intensity11\")\ntest2 <- transform.fct(\"Right.turn.intensity12\")\n```\n:::\n\n\n:::\n\n\n## Basic GLM Models\n\n::: {.panel-tabset}\n\n### Single intercept\n\nA baseline model corresponding to a Generalized Linear Model (GLM) with intercept and predicting for each contract only the observed mean multiplied by the observed frequency is used as a point of comparison.\n\n\n\n::: {#tbl-Pscore_base_sev .cell tbl-cap='Prediction scores for the base model (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model on each fold\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n  learn <- train2[train2$fold != i,]\n  valid <- train2[train2$fold == i,]\n  \n  mean <- sum(learn$AMT_Claim)/sum(learn$NB_Claim) \n  variance <- sd(learn$AMT_Claim)^2\n  phi <- variance/mean(learn$AMT_Claim)^2\n  learn$pred.base <- mean*learn$NB_Claim\n  valid$pred.base <- mean*valid$NB_Claim\n  \n  Result_ <- rbind(Result_, c(i, Score.pred.sev(valid$pred.base, valid$AMT_Claim, phi)/nrow(valid)))\n  Result2_ <- rbind(Result2_, c(i, Score.pred.sev(valid$pred.base, valid$AMT_Claim, phi)))\n}\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\n\nResult.base <- Result_  \nBase <- Result.base[nb.fold+1,]\n\nknitr::kable(Result_, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 9.28096 </td>\n   <td style=\"text-align:center;\"> 48.72725 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 9.28378 </td>\n   <td style=\"text-align:center;\"> 21.80556 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.30844 </td>\n   <td style=\"text-align:center;\"> 31.17175 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 9.34049 </td>\n   <td style=\"text-align:center;\"> 30.61554 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 9.26105 </td>\n   <td style=\"text-align:center;\"> 18.96634 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 9.29513 </td>\n   <td style=\"text-align:center;\"> 30.43693 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe model is, therefore, estimated on the entire *train* database, and the predictions are made on the *test* database, which was not used during the calibration phase.\n\n\n::: {#tbl-Pscore_basetest_sev_tel .cell tbl-cap='Prediction scores for the base model (testing set) (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nmean <- sum(train2$AMT_Claim)/sum(train2$NB_Claim) \nvariance <- sd(train2$AMT_Claim)^2\nphi <- variance/mean(train2$AMT_Claim)^2 \n  \ntest2$pred.base <- mean*test2$NB_Claim\n\nResult_ <- data.frame(t(Score.pred.sev(test2$pred.base, test2$AMT_Claim, phi)/nrow(test2)))\nResult_ <- cbind('Base', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\")\n\nResult_all <- Result_\n\nknitr::kable(Result_all, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 9.29504 </td>\n   <td style=\"text-align:center;\"> 21.82679 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n### Categorical covariates\n  \nA first regression approach is attempted using only the traditional categorical variables, namely:  \n  \n- Gender,  \n- Marital status,  \n- Vehicle usage,  \n- Region.\n\nEven though territory should also be considered since it consists of more than fifty different factors, it will not be integrated into the model immediately.  \nAs we saw in the overview of variables in a previous section, the insured gender did not appear to be an important variable for predicting the number of claims. \nThis GLM approach confirms this observation. Therefore, this variable is excluded from the model. \nIn the table below, we can see the impact of adding traditional variables on the prediction quality.\n\nBelow are the prediction scores of the model with all categorical covariates. As expected, the addition of segmentation variables improves the prediction scores compared to the simple baseline model with only an intercept.\n\n\n::: {#tbl-Pscore_GLM1_sev .cell tbl-cap='Prediction scores for the GLM1 model (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model \nscore.base <- as.formula(M_Claim ~ 1)\nscore.glm <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region )\n\n## Model on each fold\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n  learn <- train2[train2$fold != i,]\n  valid <- train2[train2$fold == i,]\n  glm.fit <- glm(score.glm, family = Gamma(link = \"log\"), data = learn)\n  \n  learn$pred.base <- predict(glm.fit, newdata=learn, type='response')*learn$NB_Claim\n  valid$pred.base <- predict(glm.fit, newdata=valid, type='response')*valid$NB_Claim\n  phi <- summary(glm.fit)$dispersion\n  \n  Result_ <- rbind(Result_, c(i, Score.pred.sev(valid$pred.base, valid$AMT_Claim, phi)/nrow(valid)))\n  Result2_ <- rbind(Result2_, c(i, Score.pred.sev(valid$pred.base, valid$AMT_Claim, phi)))\n}\n\n## Model on all data from train\nglm.base <- glm(score.base, family = Gamma(link = \"log\"), data = train2)\nglm.fit <- glm(score.glm, family = Gamma(link = \"log\"), data = train2)\ntrain2$pred.glm1 <- predict(glm.fit, newdata=train2, type='response')*train2$NB_Claim\nResult.glm1 <- Result_  \n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:3){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 9.26014 </td>\n   <td style=\"text-align:center;\"> 47.85313 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 9.25790 </td>\n   <td style=\"text-align:center;\"> 22.01984 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.28552 </td>\n   <td style=\"text-align:center;\"> 31.20756 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 9.31168 </td>\n   <td style=\"text-align:center;\"> 30.29863 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 9.23947 </td>\n   <td style=\"text-align:center;\"> 18.59595 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 9.27110 </td>\n   <td style=\"text-align:center;\"> 30.17198 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.02403 </td>\n   <td style=\"text-align:center;\"> -0.26495 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {#tbl-Pscore_basetest2_sev .cell tbl-cap='Prediction scores for the GLM model with traditional covariates (testing set) (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nscore.glm <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region )\n\nglm.fit <- glm(score.glm, family = Gamma(link = \"log\"), data = train2)\ntest2$pred.base <- predict(glm.fit, newdata=test2, type='response')*test2$NB_Claim\nphi <- summary(glm.fit)$dispersion\n\nResult_ <- data.frame(t(Score.pred.sev(test2$pred.base, test2$AMT_Claim, phi)/nrow(test2)))\nResult_ <- cbind('GLM (trad.)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 9.29504 </td>\n   <td style=\"text-align:center;\"> 21.82679 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 9.27546 </td>\n   <td style=\"text-align:center;\"> 21.77177 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n### Estimated Parameters\n\nThe table below shows the estimators obtained for the GLM-Gamma approach and compares them with the baseline model having only an intercept.\n\n\n::: {#tbl-CoeffGLM_sev .cell tbl-cap='Estimated parameters for the GLM1 model (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\n## Model \nscore.base <- as.formula(M_Claim ~ 1)\nscore.glm <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region)\n\n## Model on all data from train\nglm.base <- glm(score.base, family = Gamma(link = \"log\"), data = train2)\nglm.fit <- glm(score.glm, family = Gamma(link = \"log\"), data = train2)\n\ntab_model(glm.base, glm.fit, transform = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">M Claim</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">M Claim</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.07&nbsp;&ndash;&nbsp;8.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">7.76</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">7.46&nbsp;&ndash;&nbsp;8.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Insured sex [Male]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.04&nbsp;&ndash;&nbsp;0.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.196</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Marital [Single]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03&nbsp;&ndash;&nbsp;0.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.013</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Commute]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.28</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.03&nbsp;&ndash;&nbsp;0.56</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.061</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Farmer]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.93</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.65&nbsp;&ndash;&nbsp;-0.06</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.019</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Car use [Private]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.32&nbsp;&ndash;&nbsp;0.27</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.936</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Region [Urban]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.03&nbsp;&ndash;&nbsp;0.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.112</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">3091</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">3091</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Nagelkerke</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.000</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.045</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n:::\n  \n## GLM-Net\n  \nSome traditional continuous segmentation variables are available:  \n\n  - Credit score,   \n  - Age of the insured,  \n  - Age of the vehicle,  \n  - Number of claim-free years.\n\nFurthermore, the territory is also treated as a continuous variable.\n\nAn approach using Generalized Additive Models (GAM) theory will first be introduced for all these continuous variables. \nThis will allow us to observe the general form of the covariate to explain the number of claims. \nA parametric form will then be proposed to achieve the best possible correspondence with the spline obtained by the GAM.\n\n### Parametric transformation of continuous covariates\n\n::: {.panel-tabset}\n\n### Credit Score\n\nThe first covariate studied is the credit score. We include all categorical variables in the analysis and apply a spline approach with a GAM. The spline analysis indicates that the following parametric form appears to be appropriate for capturing the relationship:\n\n  $$s(Credit.Score) \\approx Credit.Score + Credit.Score^2$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing of the credit score (severity)](severityVarTrad_files/figure-html/fig-CS_GAM_sev-1.png){#fig-CS_GAM_sev width=864}\n:::\n:::\n\n\n### Age of the insured\n\nA spline to examine the relationship between the age of the insured and the claim deverity has also been produced. The most appropriate parametric form is as follows:\n  $$s(Insured.age) \\approx Insured.age  + Insured.age^2$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing of the age of the insured (severity)](severityVarTrad_files/figure-html/fig-IA_GAM_sev-1.png){#fig-IA_GAM_sev width=864}\n:::\n:::\n\n\n### Age of the car\n\nThe link between the response variable and the car age is approximated by\n\n$$s(Car.age) \\approx Car.age + Car.age^2 + Car.age^3$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing of the age of the car (severity)](severityVarTrad_files/figure-html/fig-CA_GAM_sev-1.png){#fig-CA_GAM_sev width=864}\n:::\n:::\n\n\n### Years without claims\n\nFinally, the link between the response variable and the number of year(s) without claims is best approximated by\n\n  $$s(Years.noclaims) \\approx Years.noclaims + Years.noclaims^2 + Years.noclaims^3$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing of years without claim (severity)](severityVarTrad_files/figure-html/fig-YNC_GAM_sev-1.png){#fig-YNC_GAM_sev width=864}\n:::\n:::\n\n\n### Territory\n\nWe proceed with the covariate Territory as we did for the analysis of the frequency. \nThe parametric function is:\n\n  $$s(terr.code) \\approx terr.code + terr.code^2 + terr.code^3$$\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing of the territories (encoded) (severity)](severityVarTrad_files/figure-html/fig-terrcode_GAM_sev-1.png){#fig-terrcode_GAM_sev width=864}\n:::\n:::\n\n\n:::\n\n\n### Fitting the GLM-Net model\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.panel-tabset}\n\n### Optimal value\n\nThe parameters of the GLM-net were calibrated using cross-validation to obtain the model hyperparameters. \nUsing these values, we can calculate the prediction scores of the model based on all covariates.\n\n\n::: {#tbl-Pscore_GLMnet1_sev .cell tbl-cap='Prediction scores for the GLM-net model (alpha=1) (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region\n                                  + Credit.score +  I(Credit.score^2) \n                                  + Insured.age + I(Insured.age^2) \n                                  + Car.age + I(Car.age^2) + I(Car.age^3)\n                                  + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                                  + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n    learn <- train2[train2$fold != i,]\n    valid <- train2[train2$fold == i,]\n    \n    matrix.x <- model.matrix(glm.score, data=learn)[,-1]\n    y <- learn$M_Claim\n\n    lambda.min <- 0.01995262\n    lambda.1se <- 0.07943282\n    \n    lambda.select <- lambda.min\n    fit <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=FALSE, alpha = 0.6, lambda = lambda.select)\n    learn$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*learn$NB_Claim\n    \n    \n    matrix.x <- model.matrix(glm.score, data=valid)[,-1]\n    y <- valid$M_Claim\n\n    valid$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*valid$NB_Claim\n    variance <- (sum((learn$AMT_Claim - learn$pred)^2)/(nrow(learn) - length(fit$beta)))\n    phi <- variance/mean(learn$AMT_Claim)^2\n    \n    Result_ <- rbind(Result_, c(i, Score.pred.sev(valid$pred, valid$AMT_Claim, phi)/nrow(valid)))\n    Result2_ <- rbind(Result2_, c(i, Score.pred.sev(valid$pred, valid$AMT_Claim, phi)))\n}\n\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:3){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 9.20427 </td>\n   <td style=\"text-align:center;\"> 45.11001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 9.22953 </td>\n   <td style=\"text-align:center;\"> 20.98561 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.24011 </td>\n   <td style=\"text-align:center;\"> 28.93837 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 9.27740 </td>\n   <td style=\"text-align:center;\"> 28.99576 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 9.21277 </td>\n   <td style=\"text-align:center;\"> 17.93211 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 9.23286 </td>\n   <td style=\"text-align:center;\"> 28.56121 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.06228 </td>\n   <td style=\"text-align:center;\"> -1.87573 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nThe same model can be used to compute the scores on the *test* set.\n  \n\n::: {#tbl-Pscore_basetest3_sev_tel .cell tbl-cap='Prediction scores for the GLM-net model  (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region\n                                  + Credit.score +  I(Credit.score^2) \n                                  + Insured.age + I(Insured.age^2) \n                                  + Car.age + I(Car.age^2) + I(Car.age^3)\n                                  + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                                  + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$M_Claim\n\nlambda.min <- 0.01995262\nlambda.1se <- 0.07943282\n\nlambda.select <- lambda.min\nfit <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=FALSE, alpha = 0.6, lambda = lambda.select)\n#fit <- glmnet(matrix.x, y, family = \"poisson\", relax=TRUE, offset = offset, alpha = 0.6, lambda = lambda.select)\n\ntrain2$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*train2$NB_Claim\ntrain2$pred.tele <- train2$pred\n\nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$M_Claim\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*test2$NB_Claim\nvariance <- (sum((train2$AMT_Claim - train2$pred)^2)/(nrow(train2) - length(fit$beta)))\nphi <- variance/mean(train2$AMT_Claim)^2\n\nResult_ <- data.frame(t(Score.pred.sev(test2$pred.base, test2$AMT_Claim, phi)/nrow(test2)))\nResult_ <- cbind('LASSO (optimal)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 9.29504 </td>\n   <td style=\"text-align:center;\"> 21.82679 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 9.27546 </td>\n   <td style=\"text-align:center;\"> 21.77177 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 9.23357 </td>\n   <td style=\"text-align:center;\"> 20.23523 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n### Parsimonious model\n\nInstead of using the optimal value of the penalty $\\lambda$  in the elastic-net approach, it is often advised to use a penalty value located at one standard error ($\\lambda_{1se}$). \nThis helps to obtain a more parsimonious model. The prediction scores of such a model are displayed below.\n\n\n::: {#tbl-Pscore_GLMnet2_sev .cell tbl-cap='Prediction scores for the GLM-net model (alpha=1) (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nResult_  <- data.frame()\nResult2_  <- data.frame()\nfor(i in 1:nb.fold) {\n  learn <- train2[train2$fold != i,]\n  valid <- train2[train2$fold == i,]\n  \n  matrix.x <- model.matrix(glm.score, data=learn)[,-1]\n  y <- learn$M_Claim\n  \n  lambda.min <- 0.01995262\n  lambda.1se <- 0.07943282\n  \n  lambda.select <- lambda.1se\n  fit <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=TRUE, alpha = 0.6, lambda = lambda.select)\n  learn$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*learn$NB_Claim\n  \n  matrix.x <- model.matrix(glm.score, data=valid)[,-1]\n  y <- valid$M_Claim\n\n  \n  valid$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*valid$NB_Claim\n  variance <- (sum((learn$AMT_Claim - learn$pred)^2)/(nrow(learn) - length(fit$beta)))\n  phi <- variance/mean(learn$AMT_Claim)^2\n  \n  Result_ <- rbind(Result_, c(i, Score.pred.sev(valid$pred, valid$AMT_Claim, phi)/nrow(valid)))\n  Result2_ <- rbind(Result2_, c(i, Score.pred.sev(valid$pred, valid$AMT_Claim, phi)))\n}\n\n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ncolnames(Result2_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\ntot <- colSums(Result2_)/nrow(train2)\ntot$Fold <- 'Total'\nResult_ <- rbind(Result_ , tot)\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:3){\n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 9.21249 </td>\n   <td style=\"text-align:center;\"> 45.73294 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 9.22998 </td>\n   <td style=\"text-align:center;\"> 20.68548 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.24605 </td>\n   <td style=\"text-align:center;\"> 29.09385 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 9.28279 </td>\n   <td style=\"text-align:center;\"> 29.08124 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 9.21318 </td>\n   <td style=\"text-align:center;\"> 17.88075 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 9.23698 </td>\n   <td style=\"text-align:center;\"> 28.66605 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.05816 </td>\n   <td style=\"text-align:center;\"> -1.77089 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe same model can be used to compute the scores on the *test* set.\n  \n\n::: {#tbl-Pscore_basetest3_sev_tel2 .cell tbl-cap='Prediction scores for the GLM-net model  (testing set)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region\n                                  + Credit.score +  I(Credit.score^2) \n                                  + Insured.age + I(Insured.age^2) \n                                  + Car.age + I(Car.age^2) + I(Car.age^3)\n                                  + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                                  + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$M_Claim\n\nlambda.min <- 0.01995262\nlambda.1se <- 0.07943282\n\nlambda.select <- lambda.1se\n#fit <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=FALSE, alpha = 0.6, lambda = lambda.select)\nfit <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=TRUE, alpha = 0.6, lambda = lambda.select)\n\ntrain2$pred <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*train2$NB_Claim\ntrain2$pred.tele <- train2$pred\n\nmatrix.x <- model.matrix(glm.score, data=test2)[,-1]\ny <- test2$M_Claim\n\ntest2$pred.base <- predict(fit, newx = matrix.x, type='response', lambda = lambda.select)*test2$NB_Claim\nvariance <- (sum((train2$AMT_Claim - train2$pred)^2)/(nrow(train2) - length(fit$beta)))\nphi <- variance/mean(train2$AMT_Claim)^2\n\nResult_ <- data.frame(t(Score.pred.sev(test2$pred.base, test2$AMT_Claim, phi)/nrow(test2)))\nResult_ <- cbind('LASSO (parsimonious)', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 9.29504 </td>\n   <td style=\"text-align:center;\"> 21.82679 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 9.27546 </td>\n   <td style=\"text-align:center;\"> 21.77177 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 9.23357 </td>\n   <td style=\"text-align:center;\"> 20.23523 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 9.23729 </td>\n   <td style=\"text-align:center;\"> 20.21870 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n### Categorical covariates\n\nFor categorical variables, the relativity values obtained for both GLM-net approaches are displayed below.\n\n\n::: {#fig-GLMnetcat_sev .cell layout-nrow=\"2\" layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Sex of the insured](severityVarTrad_files/figure-html/fig-GLMnetcat_sev-1.png){#fig-GLMnetcat_sev-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Marital status of the insured](severityVarTrad_files/figure-html/fig-GLMnetcat_sev-2.png){#fig-GLMnetcat_sev-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Car use](severityVarTrad_files/figure-html/fig-GLMnetcat_sev-3.png){#fig-GLMnetcat_sev-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Region](severityVarTrad_files/figure-html/fig-GLMnetcat_sev-4.png){#fig-GLMnetcat_sev-4 width=672}\n:::\n\nInterprétation des variables catégorielles du GLM-net (severity)\n:::\n\n\n### Continuous covariates\n\nAs with categorical variables, the relativities obtained are illustrated below for continuous variables. \n\n\n::: {#fig-GLMnet_sev .cell layout-nrow=\"3\" layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nglm.score <- as.formula(M_Claim ~ Insured.sex + Marital  +  Car.use + Region\n                        + Credit.score +  I(Credit.score^2) \n                        + Insured.age + I(Insured.age^2) \n                        + Car.age + I(Car.age^2) + I(Car.age^3) \n                        + Years.noclaims + I(Years.noclaims^2)  + I(Years.noclaims^3) \n                        + terr.code + I(terr.code^2)  + I(terr.code^3) )\n\nmatrix.x <- model.matrix(glm.score, data=train2)[,-1]\ny <- train2$M_Claim\n\n\nlambda.min <- 0.01995262\nlambda.1se <- 0.07943282\n\nlasso.min <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=FALSE, alpha = 0.6, lambda = lambda.min)\nlasso.1se <- glmnet(matrix.x, y, family = Gamma(link = \"log\"), relax=TRUE, alpha = 0.6, lambda = lambda.1se)\n#cbind(coef(lasso.min), coef(lasso.1se))\n\n### Credit Score ###\nCredit.score <- seq(from=min(train2$Credit.score), to=max(train2$Credit.score), by=1)\n\nbeta <- coef(lasso.1se)[8:9]\ncurve1 <- exp(beta[1]*Credit.score + beta[2]*Credit.score^2) \nbase1 <- exp(beta[1]*mean(train2$Credit.score) + beta[2]*mean(train2$Credit.score)^2) \n\nbeta <- coef(lasso.min)[8:9]\ncurve2 <- exp(beta[1]*Credit.score + beta[2]*Credit.score^2) \nbase2 <- exp(beta[1]*mean(train2$Credit.score) + beta[2]*mean(train2$Credit.score)^2) \n\ncurve1 <- curve1/base1\ncurve2 <- curve2/base2\ndb <- data.frame(cbind(Credit.score, curve1, curve2))\n\nggplot()+\n  geom_line(aes(x=Credit.score, y=curve1, color = 'lambda.1se' ), data=db)+\n  geom_line(aes(x=Credit.score, y=curve2, color = 'lambda.min' ), data=db)+\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Credit Score',\n       y = 'Relativity') +\n  theme_bw()\n\n### Insured.age \nInsured.age <- seq(from=min(train2$Insured.age ), to=max(train2$Insured.age ), by=1)\nbeta <- coef(lasso.1se)[10:11]\ncurve1 <- exp(beta[1]*Insured.age  + beta[2]*Insured.age^2)       \nbase1  <- exp(beta[1]*mean(train2$Insured.age) + beta[2]*mean(train2$Insured.age)^2) \n\nbeta <- coef(lasso.min)[10:11]\ncurve2 <- exp(beta[1]*Insured.age  + beta[2]*Insured.age^2)       \nbase2  <- exp(beta[1]*mean(train2$Insured.age) + beta[2]*mean(train2$Insured.age)^2) \n\ncurve1 <- curve1/base1\ncurve2 <- curve2/base2\ndb <- data.frame(cbind(Insured.age, curve1, curve2))\n\nggplot()+\n  geom_line(aes(x=Insured.age, y=curve1, color = 'lambda.1se' ), data=db)+\n  geom_line(aes(x=Insured.age, y=curve2, color = 'lambda.min' ), data=db)+\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Age of the insured',\n       y = 'Relativity') +\n  theme_bw()\n\n\n### Car Age ###\nCar.age <- seq(from=min(train2$Car.age), to=max(train2$Car.age), by=1)\nbeta <- coef(lasso.1se)[12:14]\ncurve1 <- exp(beta[1]*Car.age + beta[2]*Car.age^2 + beta[3]*Car.age^3)\nbase1  <- exp(beta[1]*mean(train2$Car.age) + beta[2]*mean(train2$Car.age)^2 + beta[3]*mean(train2$Car.age)^3) \n\nbeta <- coef(lasso.min)[12:14]\ncurve2 <- exp(beta[1]*Car.age + beta[2]*Car.age^2 + beta[3]*Car.age^3)\nbase2  <- exp(beta[1]*mean(train2$Car.age) + beta[2]*mean(train2$Car.age)^2 + beta[3]*mean(train2$Car.age)^3) \n\ncurve1 <- curve1/base1\ncurve2 <- curve2/base2\ndb <- data.frame(cbind(Car.age, curve1, curve2))\n\nggplot()+\n  geom_line(aes(x=Car.age, y=curve1, color = 'lambda.1se' ), data=db)+\n  geom_line(aes(x=Car.age, y=curve2, color = 'lambda.min' ), data=db)+\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Age of the car',\n       y = 'Relativity') +\n  theme_bw()\n\n### Years.noclaims \nYears.noclaims <- seq(from=min(train2$Years.noclaims ), to=max(train2$Years.noclaims ), by=1)\nbeta <- coef(lasso.1se)[15:17]\ncurve1 <- exp(beta[1]*Years.noclaims  + beta[2]*Years.noclaims^2 + beta[3]*Years.noclaims ^3)        \nbase1  <- exp(beta[1]*mean(train2$Years.noclaims) + beta[2]*mean(train2$Years.noclaims)^2 + beta[3]*mean(train2$Years.noclaims)^3) \n\nbeta <- coef(lasso.min)[15:17]\ncurve2 <- exp(beta[1]*Years.noclaims  + beta[2]*Years.noclaims^2 + beta[3]*Years.noclaims ^3)        \nbase2  <- exp(beta[1]*mean(train2$Years.noclaims) + beta[2]*mean(train2$Years.noclaims)^2 + beta[3]*mean(train2$Years.noclaims)^3) \n\ncurve1 <- curve1/base1\ncurve2 <- curve2/base2\ndb <- data.frame(cbind(Years.noclaims, curve1, curve2))\n\nggplot()+\n  geom_line(aes(x=Years.noclaims, y=curve1, color = 'lambda.1se' ), data=db)+\n  geom_line(aes(x=Years.noclaims, y=curve2, color = 'lambda.min' ), data=db)+\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Years without claim',\n       y = 'Relativity') +\n  theme_bw()\n\n### terr.code  \nterr.code  <- seq(from=min(train2$terr.code  ), to=max(train2$terr.code  ), by=0.01)\nbeta <- coef(lasso.1se)[18:20]\ncurve1 <- exp(beta[1]*terr.code + beta[2]*terr.code^2 + beta[3]*terr.code^3)\nbase1  <- exp(beta[1]*mean(train2$terr.code) + beta[2]*mean(train2$terr.code)^2 + beta[3]*mean(train2$terr.code)^3)\n\nbeta <- coef(lasso.min)[18:20]\ncurve2 <- exp(beta[1]*terr.code + beta[2]*terr.code^2 + beta[3]*terr.code^3)\nbase2  <- exp(beta[1]*mean(train2$terr.code) + beta[2]*mean(train2$terr.code)^2 + beta[3]*mean(train2$terr.code)^3)\n\ncurve1 <- curve1/base1\ncurve2 <- curve2/base2\ndb <- data.frame(cbind(terr.code, curve1, curve2))\n\nggplot()+\n  geom_line(aes(x=terr.code, y=curve1, color = 'lambda.1se' ), data=db)+\n  geom_line(aes(x=terr.code, y=curve2, color = 'lambda.min' ), data=db)+\n  guides(color = guide_legend(title = \"\")) +\n  labs(x = 'Territory (encoded)',\n       y = 'Relativity') +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Credit Score](severityVarTrad_files/figure-html/fig-GLMnet_sev-1.png){#fig-GLMnet_sev-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Annal Miles Drive](severityVarTrad_files/figure-html/fig-GLMnet_sev-2.png){#fig-GLMnet_sev-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Age of the car](severityVarTrad_files/figure-html/fig-GLMnet_sev-3.png){#fig-GLMnet_sev-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Age of the insured](severityVarTrad_files/figure-html/fig-GLMnet_sev-4.png){#fig-GLMnet_sev-4 width=672}\n:::\n\n::: {.cell-output-display}\n![Years without claim](severityVarTrad_files/figure-html/fig-GLMnet_sev-5.png){#fig-GLMnet_sev-5 width=672}\n:::\n\nInterprétation des variables continues du GLM-net (severity)\n:::\n\n\n:::\n  \n## XGBoost\n\nAs we did for the analysis of claim frequency, we also consider the XGBoost approach for claim severity. We utilized Bayesian optimization to find the hyperparameters of the model.\n  \n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {.panel-tabset}\n\n### Prediction Scores\n\nUsing the hyperparameters we identified, we can calculate the model's prediction scores. The obtained scores demonstrate a notable enhancement compared to alternative approaches evaluated.\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-Pscore_XGBoost_sev .cell tbl-cap='Prediction scores for the XGBoost model (severity)' hash='severityVarTrad_cache/html/tbl-Pscore_XGBoost_sev_84b870d2bfefceecaf59d953887c1919'}\n\n```{.r .cell-code  code-fold=\"true\"}\nparam <- list(\n  eta = 0.1442358,\n  max_depth = 4,\n  subsample = 0.4589511,\n  min_child_weight = 121.1358,\n  booster = \"gbtree\",\n  objective = \"reg:gamma\",\n  eval_metric = \"gamma-nloglik\")\n\nset.seed(333)\nxgbcv <- xgb.cv(params = param,\n                nrounds = 120,\n                data = dtrain,\n                folds = folds,\n                prediction = TRUE,\n                early_stopping_rounds = 10,\n                verbose = 0,\n                maximize = F)\n\n\nvariance <- sapply(xgbcv$folds, function(x){sum((train2$AMT_Claim[x]-unlist(xgbcv$pred[x])*train2$NB_Claim[x])^2)/length(train2$AMT_Claim[x])})  \nmean <- sapply(xgbcv$folds, function(x){mean(train2$AMT_Claim[x])})\nphi <- unlist(variance)/mean^2\n\nSc.log1 <- -dgamma(train2$AMT_Claim[xgbcv$folds$fold1], shape = 1/phi[1], scale = unlist(xgbcv$pred[xgbcv$folds$fold1])*train2$NB_Claim[xgbcv$folds$fold1]*phi[1], log=TRUE)\nSc.log2 <- -dgamma(train2$AMT_Claim[xgbcv$folds$fold2], shape = 1/phi[2], scale = unlist(xgbcv$pred[xgbcv$folds$fold2])*train2$NB_Claim[xgbcv$folds$fold2]*phi[2], log=TRUE)\nSc.log3 <- -dgamma(train2$AMT_Claim[xgbcv$folds$fold3], shape = 1/phi[3], scale = unlist(xgbcv$pred[xgbcv$folds$fold3])*train2$NB_Claim[xgbcv$folds$fold3]*phi[3], log=TRUE)\nSc.log4 <- -dgamma(train2$AMT_Claim[xgbcv$folds$fold4], shape = 1/phi[4], scale = unlist(xgbcv$pred[xgbcv$folds$fold4])*train2$NB_Claim[xgbcv$folds$fold4]*phi[4], log=TRUE)\nSc.log5 <- -dgamma(train2$AMT_Claim[xgbcv$folds$fold5], shape = 1/phi[5], scale = unlist(xgbcv$pred[xgbcv$folds$fold5])*train2$NB_Claim[xgbcv$folds$fold5]*phi[5], log=TRUE)\n\nSc.MSE <- sapply(xgbcv$folds, function(x){(train2$AMT_Claim[x]-unlist(xgbcv$pred[x])*train2$NB_Claim[x])^2/1000000})\n\n\nResult_  <- rbind(\n  c(1,mean(Sc.log1), mean(Sc.MSE[1]$fold1)),\n  c(2,mean(Sc.log2), mean(Sc.MSE[2]$fold2)),\n  c(3,mean(Sc.log3), mean(Sc.MSE[3]$fold3)),\n  c(4,mean(Sc.log4), mean(Sc.MSE[4]$fold4)),\n  c(5,mean(Sc.log5), mean(Sc.MSE[5]$fold5))\n)\n\nRes.sum  <- rbind(\n  c(sum(Sc.log1), sum(Sc.MSE[1]$fold1)),\n  c(sum(Sc.log2), sum(Sc.MSE[2]$fold2)),\n  c(sum(Sc.log3), sum(Sc.MSE[3]$fold3)),\n  c(sum(Sc.log4), sum(Sc.MSE[4]$fold4)),\n  c(sum(Sc.log5), sum(Sc.MSE[5]$fold5))\n)\nsum <- c('Total', colSums(Res.sum)/nrow(train2))\n\nResult_  <- data.frame(rbind(Result_, sum)) \n\n## Show results\ncolnames(Result_) <- c('Fold', \"Sc.log\", \"Sc.MSE\")\nResult_ <- rbind(Result_, Base)\n\nResult_[nb.fold+2,1] <- 'Improvement'\n\nfor(i in 2:3){\n  Result_[,i] <- as.numeric(Result_[,i])  \n  Result_[nb.fold+2,i] <-  Result_[nb.fold+1,i] - Result_[nb.fold+2,i]\n}\n\nrownames(Result_) <- NULL\nknitr::kable(Result_, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fold </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 9.35734 </td>\n   <td style=\"text-align:center;\"> 44.35244 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 9.14014 </td>\n   <td style=\"text-align:center;\"> 20.12582 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.21035 </td>\n   <td style=\"text-align:center;\"> 28.22455 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 9.23525 </td>\n   <td style=\"text-align:center;\"> 28.30773 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 9.09730 </td>\n   <td style=\"text-align:center;\"> 17.68123 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 9.20981 </td>\n   <td style=\"text-align:center;\"> 27.90189 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Improvement </td>\n   <td style=\"text-align:center;\"> -0.08533 </td>\n   <td style=\"text-align:center;\"> -2.53505 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nThe same model can be used to compute the scores on the *test* set.  We also observe that the XGBoost approach is the most effective.\n\n\n::: {#tbl-Pscore_XGBoost_correction333_sev_tel .cell tbl-cap='Prediction scores for the XGBoost model with traditional covariates (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nparam <- list(\n  eta = 0.1442358,\n  max_depth = 4,\n  subsample = 0.4589511,\n  min_child_weight = 121.1358,\n  booster = \"gbtree\",\n  objective = \"reg:gamma\",\n  eval_metric = \"gamma-nloglik\")\n\nset.seed(633)\nfit.xgb <- xgb.train(params = param,\n                     nrounds = 120,\n                     data = dtrain)\n\ntrain2$pred.xgb <- predict(fit.xgb, dtrain, type='response')*train2$NB_Claim\ntrain2$pred.xgb.off <- predict(fit.xgb, dtrain, type='response')\n\ndtest <- xgb.DMatrix(data = data.matrix(test2[, paste(trad.vars)]), label = test2$M_Claim)\n#setinfo(dtest,\"base_margin\",log(test2$expo))\ntest2$pred.xgb <- predict(fit.xgb, dtest, type='response')*test2$NB_Claim\ntest2$pred.xgb.off <- predict(fit.xgb, dtest, type='response')\n\ntest2$pred.base <- test2$pred.xgb\n\nvariance <- (sum((train2$pred.xgb - (train2$AMT_Claim))^2)/(length(train2$AMT_Claim)))\nphi <- variance/mean(train2$AMT_Claim)^2\n\nResult_ <- data.frame(t(Score.pred.sev(test2$pred.base, test2$AMT_Claim, phi)/nrow(test2)))\nResult_ <- cbind('XGBoost', Result_)\ncolnames(Result_) <- c(\"Model\", \"Sc.log\", \"Sc.MSE\")\n\nResult_all <- rbind(Result_all, Result_)\n\nknitr::kable(Result_all, align = \"ccc\", digits = c(0, 5, 5), format.args = list(big.mark = \",\"))%>%   \n  kable_styling(bootstrap_options = \"striped\", full_width = F)  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Model </th>\n   <th style=\"text-align:center;\"> Sc.log </th>\n   <th style=\"text-align:center;\"> Sc.MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Base </td>\n   <td style=\"text-align:center;\"> 9.29504 </td>\n   <td style=\"text-align:center;\"> 21.82679 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> GLM (trad.) </td>\n   <td style=\"text-align:center;\"> 9.27546 </td>\n   <td style=\"text-align:center;\"> 21.77177 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (optimal) </td>\n   <td style=\"text-align:center;\"> 9.23357 </td>\n   <td style=\"text-align:center;\"> 20.23523 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> LASSO (parsimonious) </td>\n   <td style=\"text-align:center;\"> 9.23729 </td>\n   <td style=\"text-align:center;\"> 20.21870 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> XGBoost </td>\n   <td style=\"text-align:center;\"> 9.19011 </td>\n   <td style=\"text-align:center;\"> 20.06725 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\n### Variables Importance\n\nThe following graph depicts the most crucial variables in the XGBoost model.\n\n\n::: {#tbl-VI_XGBoost_sev .cell tbl-cap='Variables importance for the XGBoost model (severity)'}\n\n```{.r .cell-code  code-fold=\"true\"}\nparam <- list(\n  eta = 0.1442358,\n  max_depth = 4,\n  subsample = 0.4589511,\n  min_child_weight = 121.1358,\n  booster = \"gbtree\",\n  objective = \"reg:gamma\",\n  eval_metric = \"gamma-nloglik\")\n\nset.seed(333)\nfit.xgb <- xgb.train(params = param,\n                     nrounds = 120,\n                     data = dtrain,\n#                     prediction = TRUE,\n                     verbose = 0,\n                     maximize = F)\n\nimportance_matrix <- xgb.importance(dimnames(dtrain)[[2]], model = fit.xgb)\nxgb.ggplot.importance(importance_matrix,top_n=10) + theme(text = element_text(size=15))\n```\n\n::: {.cell-output-display}\n![](severityVarTrad_files/figure-html/tbl-VI_XGBoost_sev-1.png){width=672}\n:::\n:::\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}